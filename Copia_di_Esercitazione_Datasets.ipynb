{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d50cd371d08244248602eca6b3071b50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d0b7926bcff48079ec2a62d78e74cf5",
              "IPY_MODEL_02c163309c68401d977ce2b2cca11b69",
              "IPY_MODEL_29dff4adfed04f07b290c45cc9d84c0c"
            ],
            "layout": "IPY_MODEL_4726372f4cc143cda8988a2a5391aaae"
          }
        },
        "5d0b7926bcff48079ec2a62d78e74cf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1eaea5e11a8941f8847fe6790e470cb3",
            "placeholder": "​",
            "style": "IPY_MODEL_8c2be73bb0644a279a1f753e03d21b4f",
            "value": "100%"
          }
        },
        "02c163309c68401d977ce2b2cca11b69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_420f082729194cfa83ea11545150d67f",
            "max": 60000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3072a5aaec28422aa948287a74c106f6",
            "value": 60000
          }
        },
        "29dff4adfed04f07b290c45cc9d84c0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0957721cd3eb485c9ac69150cc10ff33",
            "placeholder": "​",
            "style": "IPY_MODEL_a86f6ac223ff4de29d506becc6974c1c",
            "value": " 60000/60000 [00:13&lt;00:00, 4840.75it/s]"
          }
        },
        "4726372f4cc143cda8988a2a5391aaae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1eaea5e11a8941f8847fe6790e470cb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c2be73bb0644a279a1f753e03d21b4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "420f082729194cfa83ea11545150d67f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3072a5aaec28422aa948287a74c106f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0957721cd3eb485c9ac69150cc10ff33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a86f6ac223ff4de29d506becc6974c1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3b9d437df324bff9ec396c58fc84dc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aaa1280e508e452eabe7d9cb164842fb",
              "IPY_MODEL_a71c9629808a4a0491406bfc0419c673",
              "IPY_MODEL_ab88074389eb4835bc3db46666f82600"
            ],
            "layout": "IPY_MODEL_16907439f3934b11ad1bba59f890241b"
          }
        },
        "aaa1280e508e452eabe7d9cb164842fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f84b71f10984cf8b743d31414e55a18",
            "placeholder": "​",
            "style": "IPY_MODEL_04d8568ee5d047dbbd18bde524230fee",
            "value": "100%"
          }
        },
        "a71c9629808a4a0491406bfc0419c673": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_193867506c9845e3b9a6dea3c61de494",
            "max": 1875,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_026f4f0cd7a24e37be7e68ad2292e51e",
            "value": 1875
          }
        },
        "ab88074389eb4835bc3db46666f82600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3aa11bb6911842a884c9d83ecbf76f11",
            "placeholder": "​",
            "style": "IPY_MODEL_1e523894fdcc4e3a9c9dd452fba73b6d",
            "value": " 1875/1875 [00:20&lt;00:00, 109.83it/s]"
          }
        },
        "16907439f3934b11ad1bba59f890241b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f84b71f10984cf8b743d31414e55a18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04d8568ee5d047dbbd18bde524230fee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "193867506c9845e3b9a6dea3c61de494": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "026f4f0cd7a24e37be7e68ad2292e51e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3aa11bb6911842a884c9d83ecbf76f11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e523894fdcc4e3a9c9dd452fba73b6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39496ff7a4b4485fb37e68a2d1cb75f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c73906b12fb4dd885efe8f59f5632d0",
              "IPY_MODEL_3178992e04a94e5495db1b463ea69f39",
              "IPY_MODEL_eb84202bf0c947ff8b044ed42966ddcf"
            ],
            "layout": "IPY_MODEL_b4c500c98fab4fa5b3a51247f22ea634"
          }
        },
        "7c73906b12fb4dd885efe8f59f5632d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7970871adedc4f3da6367f38a71ad3e8",
            "placeholder": "​",
            "style": "IPY_MODEL_510b5564fe5647189b527c0e7836ba1d",
            "value": "100%"
          }
        },
        "3178992e04a94e5495db1b463ea69f39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7037cbebc4c4157a45f42be2337b0f7",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb8abee4d31849b485d594ad21716e3e",
            "value": 20
          }
        },
        "eb84202bf0c947ff8b044ed42966ddcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86029d368a2c4cccb81524914d1aca77",
            "placeholder": "​",
            "style": "IPY_MODEL_11f467df100b431fa05a5f4c29a7a406",
            "value": " 20/20 [00:02&lt;00:00,  9.87it/s]"
          }
        },
        "b4c500c98fab4fa5b3a51247f22ea634": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7970871adedc4f3da6367f38a71ad3e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "510b5564fe5647189b527c0e7836ba1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7037cbebc4c4157a45f42be2337b0f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb8abee4d31849b485d594ad21716e3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "86029d368a2c4cccb81524914d1aca77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11f467df100b431fa05a5f4c29a7a406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/G-Vida/Machine_Learning/blob/main/Copia_di_Esercitazione_Datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C5Ct9yoZKYa"
      },
      "source": [
        "# MLME: Datasets, dataloaders, augmentations\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0 Table of contents\n",
        "We're going to look at the PyTorch Workflow we've been learning and look at the data preparation steps.\n",
        "\n",
        "![a PyTorch workflow with a computer vision focus](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/03-pytorch-computer-vision-workflow.png)\n",
        "\n",
        "Specifically, we're going to cover:\n",
        "\n",
        "| **Topic** | **Contents** |\n",
        "| ----- | ----- |\n",
        "| **0. PyTorch Dataset** | How do we get and prepare the data to train and evaluate our models? To practice computer vision, we'll start with some images of different pieces of clothing from [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). |\n",
        "| **1. Data visualization** | Once we have our dataset, we will try to visualize some data samples. Never forget to look at the data you have before starting to use it. |\n",
        "| **2. PyTorch Dataloader** | With the dataset up and running, we will then see how we can get samples from it to train and test our models. We will use what a DataLoader |\n",
        "| **3. Creating a custom Dataset** | \"But I do not want to use a pre-loaded dataset, I wnat my custom dataset\". Do not worry, we will look at how to create a custom dataset from the data. |\n",
        "| **4. Loading data from a Google Drive** | Speaking of custom datasets, we will also look at how to import data stored in our Google Drive to a Colab.|\n",
        "| **5. Data transformations** | An important part of the data preparation pipeline, is data pre-processing. We are going to look at how we can pre-process our data with several transformations. |"
      ],
      "metadata": {
        "id": "9Yud9FriQJmy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 Useful resources and credits.\n",
        "Official PyTorch tutorials:\n",
        "- https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
        "- https://pytorch.org/tutorials/beginner/basics/transforms_tutorial.html\n",
        "\n",
        "PyTorch Documentation\n",
        "- https://pytorch.org/docs/stable/index.html\n",
        "\n",
        "The material in this lecture draws from:\n",
        "- exercises from E. Rodolà [classes](https://erodola.github.io/DLAI-s2-2024/)\n",
        "- [Zero to Mastery Learn PyTorch for Deep Learning pt.3](https://www.learnpytorch.io/03_pytorch_computer_vision/)\n",
        "- [Zero to Mastery Learn PyTorch for Deep Learning pt.4](https://www.learnpytorch.io/04_pytorch_custom_datasets/)"
      ],
      "metadata": {
        "id": "h-VFzRQvQLXO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 How to run this notebook?\n",
        "This notebook is *view only* and uses Google Colab to run. To **run this Colab notebook**, either:\n",
        "\n",
        "- **Make a copy to your Google Drive so you can make local changes:** File > Save a copy in Drive...\n",
        "\n",
        "- **Run in playground mode:** File > Open in playground mode\n",
        "- **Download the Jupyter notebook, so you can run it on your computer configured with Jupyter:** File > Download .ipynb"
      ],
      "metadata": {
        "id": "qVUuOaypDDYR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 Preliminaries"
      ],
      "metadata": {
        "id": "GHKiAWxOGLb1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Important PyTorch libraries\n",
        "\n",
        "Before we get started writing code, let's talk about some PyTorch computer vision libraries you should be aware of.\n",
        "\n",
        "| PyTorch module | What does it do? |\n",
        "| ----- | ----- |\n",
        "| [`torchvision`](https://pytorch.org/vision/stable/index.html) | Contains datasets, model architectures and image transformations often used for computer vision problems. |\n",
        "| [`torchvision.datasets`](https://pytorch.org/vision/stable/datasets.html) | Here you'll find many example computer vision datasets for a range of problems from image classification, object detection, image captioning, video classification and more. It also contains [a series of base classes for making custom datasets](https://pytorch.org/vision/stable/datasets.html#base-classes-for-custom-datasets). |\n",
        "| [`torchvision.transforms`](https://pytorch.org/vision/stable/transforms.html) | Often images need to be transformed (turned into numbers/processed/augmented) before being used with a model, common image transformations are found here. |\n",
        "| [`torch.utils.data.Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) | Base dataset class for PyTorch.  |\n",
        "| [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html#module-torch.utils.data) | Creates a Python iterable over a dataset (created with `torch.utils.data.Dataset`). |\n",
        "\n",
        "> **Note:** The `torch.utils.data.Dataset` and `torch.utils.data.DataLoader` classes aren't only for computer vision in PyTorch, they are capable of dealing with many different types of data."
      ],
      "metadata": {
        "id": "IKJxgNrDQkW6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Visualization tools\n",
        "In this notebook we will use both **Matplotlib** and another plotting library, called **[Plotly](https://pyviz.org/overviews/index.html)**.\n",
        "Effectively communicating your findings through plots and visualizations is an essential part of any scientific or engineering project.\n",
        "\n",
        "\n",
        "Plotly is a modern library that makes interactive plots very easy to produce, and is very popular also outside of the DL community.\n",
        "[Here](https://plot.ly/python/) you can find its documentation."
      ],
      "metadata": {
        "id": "0fIp-c4KQmVz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we've covered some of the most important PyTorch computer vision libraries, let's import the relevant dependencies."
      ],
      "metadata": {
        "id": "FlpuPxnDQoPb"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRePt-K1_yw9"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset     # we import the dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tvpx3YbdcKlK"
      },
      "source": [
        "## 4 Loading a Dataset\n",
        "\n",
        "In all learning problems, we have to deal with data. Data preparation is a fundamental step before building a model.\n",
        "\n",
        "As Abraham Lossfunction said...\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/04-abraham-lossfunction.png\" alt=\"tweet by mrdbourke, if I had eight hours to build a machine learning model, I'd spend the first 6 hours preparing my dataset\" width=800/>\n",
        "\n",
        "So let's make sure we prepare our data the best possible way!\n",
        "In PyTorch (and other common frameworks) you can decouple the code that *manages* the data from the code that *uses* the data.\n",
        "\n",
        "This produces simpler and more understandable code, and enables the possibility to re-use the same dataset with different models or the same model with different datasets.\n",
        "In the following sections, we will have a glimpse into how to manage the data pipeline.\n",
        "\n",
        "To handle data, PyTorch provides [`torch.utils.data.Dataset`](https://pytorch.org/docs/stable/data.html?highlight=dataset#torch.utils.data.Dataset). The PyTorch `Dataset` class that represents a data collection and stores the samples and their corresponding labels.\n",
        "PyTorch domain libraries provide a number of pre-loaded datasets for tasks related to [computer vision](https://pytorch.org/vision/stable/datasets.html), [audio](https://pytorch.org/audio/stable/datasets.html), [text](https://pytorch.org/text/stable/datasets.html) and even [GeoAI](https://torchgeo.readthedocs.io/en/latest/api/datasets.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Load FashinMNIST\n",
        "We're going to start with a computer vision dataset: [**FashionMNIST**](https://pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html#torchvision.datasets.FashionMNIST).\n",
        "\n",
        "MNIST stands for Modified National Institute of Standards and Technology.\n",
        "\n",
        "The [original MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database) contains thousands of examples of handwritten digits (from 0 to 9) and was used to build computer vision models to identify numbers for postal services.\n",
        "\n",
        "[FashionMNIST](https://github.com/zalandoresearch/fashion-mnist), made by Zalando Research, is a similar setup.\n",
        "\n",
        "Except it contains grayscale images of 10 different kinds of clothing.\n",
        "\n",
        "![example image of FashionMNIST](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/03-fashion-mnist-slide.png)\n",
        "*`torchvision.datasets` contains a lot of example datasets you can use to practice writing computer vision code on. FashionMNIST is one of those datasets. And since it has 10 different image classes (different types of clothing), it's a multi-class classification problem.*\n",
        "\n",
        "\n",
        "To download it, we provide the following parameters:\n",
        "* `root: str` - which folder do you want to download the data to?\n",
        "* `train: Bool` - do you want the training or test split?\n",
        "* `download: Bool` - should the data be downloaded?\n",
        "* `transform: torchvision.transforms` - what transformations would you like to do on the data? (**We will discuss transformations later**)\n",
        "* `target_transform` - you can transform the targets (labels) if you like too (**We will discuss transformations later**).\n",
        "\n",
        "Many other datasets in `torchvision` have these parameter options."
      ],
      "metadata": {
        "id": "fo29REaqL2t1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have many different separated immages with different clothes => we have to understand which kind of clothing item is it!!!\n"
      ],
      "metadata": {
        "id": "6eKuHeUeIw8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup training data\n",
        "train_data = datasets.FashionMNIST(      # we pass the datasets\n",
        "    root=\"data\",    # where we want to download data\n",
        "    train=True,    # we need both a training or a test set => train = False will give the test data instead\n",
        "    download=True,    # we want to download it\n",
        "    transform=ToTensor()    # We apply it at each immage we are downloading\n",
        ")\n",
        "\n",
        "# Setup test data\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "5NOjyeo7puf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e3fe871-b3f9-4d55-8515-958392821773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 13.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 209kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.85MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 6.65MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check what is our training data"
      ],
      "metadata": {
        "id": "xG4yAEd2MzTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What's train_data? What is one sample?\n",
        "print(f\"train_data is:\\n{train_data}\\n\")\n",
        "print(f\"A single sample from train data is: {type(train_data[0])}\")\n",
        "\n",
        "# Let's check the first training sample\n",
        "image, label = train_data[0]\n"
      ],
      "metadata": {
        "id": "h10zfXonM2pt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49365c61-5fed-403f-ea06-a79c5d16a8ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data is:\n",
            "Dataset FashionMNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: data\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n",
            "\n",
            "A single sample from train data is: <class 'tuple'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've got a big tensor of values (the image) leading to a single value for the target (the label).\n",
        "\n",
        "Let's see the image shape."
      ],
      "metadata": {
        "id": "HVJ9tYjEO3uE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What's the shape of the image?\n",
        "image.shape"
      ],
      "metadata": {
        "id": "mp25b2qzO8pz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "504dde0a-a57c-4882-9fa2-34b9fb4865b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The shape of the image tensor is `[1, 28, 28]` or more specifically:\n",
        "\n",
        "```\n",
        "[color_channels=1, height=28, width=28]     \n",
        "```\n",
        "\n",
        "Having `color_channels=1` means the image is grayscale. With RGB we consider 3 dimensions.\n",
        "\n",
        "![example input and output shapes of the fashionMNIST problem](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/03-computer-vision-input-and-output-shapes.png)\n",
        "*Various problems will have various input and output shapes. But the premise remains: encode data into numbers, build a model to find patterns in those numbers, convert those patterns into something meaningful.*\n",
        "\n",
        "If `color_channels=3`, the image comes in pixel values for red, green and blue (this is also known as the [RGB color model](https://en.wikipedia.org/wiki/RGB_color_model)).\n",
        "\n",
        "The order of our current tensor is often referred to as `CHW` (Color Channels, Height, Width).\n",
        "\n",
        "There's debate on whether images should be represented as `CHW` (color channels first) or `HWC` (color channels last).\n",
        "\n",
        "> **Note:** You'll also see `NCHW` and `NHWC` formats where `N` stands for *number of images*. For example if you have a `batch_size=32`, your tensor shape may be `[32, 1, 28, 28]`. We'll cover batch sizes later.\n",
        "\n",
        "PyTorch generally accepts `NCHW` (channels first) as the default for many operators.\n",
        "\n",
        "However, PyTorch also explains that `NHWC` (channels last) performs better and is [considered best practice](https://pytorch.org/blog/tensor-memory-format-matters/#pytorch-best-practice).\n",
        "\n",
        "Let's check out more shapes of our data."
      ],
      "metadata": {
        "id": "SIPKXst2PCd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How many samples are there?\n",
        "len(train_data.data), len(train_data.targets), len(test_data.data), len(test_data.targets)"
      ],
      "metadata": {
        "id": "c-hOPFwxPS8E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2baf476-12a5-40ab-8761-b742a0ddfbbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 60000, 10000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we've got 60,000 training samples and 10,000 testing samples.\n",
        "\n",
        "What classes are there?\n",
        "\n",
        "We can find these via the `.classes` attribute."
      ],
      "metadata": {
        "id": "n3d2f9BkPWvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# See classes\n",
        "class_names = train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "id": "hfS7iuJRPXjs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea69e322-4a2b-4eb3-bfa0-abac674d6bc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['T-shirt/top',\n",
              " 'Trouser',\n",
              " 'Pullover',\n",
              " 'Dress',\n",
              " 'Coat',\n",
              " 'Sandal',\n",
              " 'Shirt',\n",
              " 'Sneaker',\n",
              " 'Bag',\n",
              " 'Ankle boot']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sweet! It looks like we're dealing with 10 different kinds of clothes.\n",
        "\n",
        "Because we're working with 10 different classes, it means our problem is **multi-class classification**.\n",
        "\n",
        "Let's get visual."
      ],
      "metadata": {
        "id": "0TIN5EiSPkkb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Visualizing the data\n",
        "Checking the number of loaded samples, their shapes and labels is important. But, since we are dealing with images, we should also look at them, to understand the kind of data we are dealing with. Since the samples are images, it is straightforward to visualize them: we just need to show the images. For other datatypes, we may decide to use different kinds of plots."
      ],
      "metadata": {
        "id": "QOMn6jsz5c_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "image, label = train_data[0]\n",
        "print(f\"Image shape: {image.shape}\")\n",
        "plt.imshow(image.squeeze()) # image shape is [1, 28, 28] (colour channels, height, width)\n",
        "plt.title(label);\n",
        "\n",
        "### If we don't define the colormap => it will automatically use a map."
      ],
      "metadata": {
        "id": "lw1dkE6rRdWk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "b88872d5-9889-4d8a-c7f4-56308f1d0dc7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b077278bdaa5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Image shape: {image.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# image shape is [1, 28, 28] (colour channels, height, width)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can turn the image into grayscale using the cmap parameter of plt.imshow()."
      ],
      "metadata": {
        "id": "gjbC39y1Rhmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(image.squeeze(), cmap=\"gray\")     # we can show the immage with imshow\n",
        "plt.title(class_names[label]);"
      ],
      "metadata": {
        "id": "VNBTVN2kRkC-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "2c9cb3a4-a6fe-4d43-d201-6ee541a58361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Beautiful, well as beautiful as a pixelated grayscale ankle boot can get.\n",
        "\n",
        "Let's view a few more."
      ],
      "metadata": {
        "id": "-jJ2_12YRq4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot more images\n",
        "torch.manual_seed(42)\n",
        "fig = plt.figure(figsize=(9, 9))\n",
        "rows, cols = 4, 4\n",
        "for i in range(1, rows * cols + 1):\n",
        "    random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
        "    img, label = train_data[random_idx]\n",
        "    fig.add_subplot(rows, cols, i)\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "    plt.title(class_names[label])\n",
        "    plt.axis(False);"
      ],
      "metadata": {
        "id": "8om5OCZo8G2_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "outputId": "79b7e8a9-9ed5-4ccd-d8eb-0bb0552c534b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x900 with 16 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hmmm, this dataset doesn't look too aesthetic.\n",
        "\n",
        "But the principles we're going to learn on how to build a model for it will be similar across a wide range of computer vision problems.\n",
        "\n",
        "In essence, taking pixel values and building a model to find patterns in them to use on future pixel values.\n",
        "\n",
        "Plus, even for this small dataset (yes, even 60,000 images in deep learning is considered quite small), could you write a program to classify each one of them?\n",
        "\n",
        "You probably could."
      ],
      "metadata": {
        "id": "8K4LQ0qcSEMS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5 📓 Exercise: load a dataset from PyTorch\n",
        "Try to do the same thing, and load a different dataset from the ones [pre-loaded in PyTorch](https://pytorch.org/vision/stable/datasets.html). For example, try with the [**FGVCAircraft**](https://pytorch.org/vision/stable/generated/torchvision.datasets.FGVCAircraft.html#torchvision.datasets.FGVCAircraft) dataset.\n",
        "\n",
        "Be mindful of the parameters this class expects. Check the documentation!\n",
        "```\n",
        "class torchvision.datasets.FGVCAircraft(root: Union[str, Path], split: str = 'trainval', annotation_level: str = 'variant', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False)\n",
        "```"
      ],
      "metadata": {
        "id": "3zRvRUaD8Z4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# try to load the FGVCAircraft dataset."
      ],
      "metadata": {
        "id": "XQibBwrFQ0rX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Solution\n",
        "train_data = datasets.FGVCAircraft(\n",
        "    root=\"data\",\n",
        "    split=\"train\",\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "print(train_data)\n",
        "img, label = train_data[100]\n",
        "print(img.shape)\n",
        "print(label)\n",
        "class_names = train_data.classes\n",
        "plt.title(class_names[label])\n",
        "# Note: permute() will change shape of image to suit matplotlib\n",
        "# (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])\n",
        "plt.imshow(img.permute(1,2,0))"
      ],
      "metadata": {
        "id": "Q8ZGiJ_98wHK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "outputId": "390d9d71-e274-42bd-8e42-d4b67aa18bb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/archives/fgvc-aircraft-2013b.tar.gz to data/fgvc-aircraft-2013b.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 262M/2.75G [01:12<11:30, 3.61MB/s]\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-13-4cc7361ae5f3>\", line 2, in <cell line: 0>\n",
            "    train_data = datasets.FGVCAircraft(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/datasets/fgvc_aircraft.py\", line 60, in __init__\n",
            "    self._download()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/datasets/fgvc_aircraft.py\", line 112, in _download\n",
            "    download_and_extract_archive(self._URL, self.root)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/datasets/utils.py\", line 395, in download_and_extract_archive\n",
            "    download_url(url, download_root, filename, md5)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/datasets/utils.py\", line 132, in download_url\n",
            "    _urlretrieve(url, fpath)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/datasets/utils.py\", line 30, in _urlretrieve\n",
            "    while chunk := response.read(chunk_size):\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/http/client.py\", line 473, in read\n",
            "    s = self.fp.read(amt)\n",
            "        ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/socket.py\", line 718, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/ssl.py\", line 1314, in recv_into\n",
            "    return self.read(nbytes, buffer)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/ssl.py\", line 1166, in read\n",
            "    return self._sslobj.read(len, buffer)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1684, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "               ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 948, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 997, in getmodule\n",
            "    os.path.realpath(f)] = module.__name__\n",
            "    ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen posixpath>\", line 416, in realpath\n",
            "  File \"<frozen posixpath>\", line 451, in _joinrealpath\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-4cc7361ae5f3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# @title Solution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m train_data = datasets.FGVCAircraft(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/fgvc_aircraft.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, split, annotation_level, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/fgvc_aircraft.py\u001b[0m in \u001b[0;36m_download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mdownload_and_extract_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_URL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m     \u001b[0mdownload_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Downloading \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" to \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0m_urlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mURLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36m_urlretrieve\u001b[0;34m(url, filename, chunk_size)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                 \u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    472\u001b[0m                 \u001b[0mamt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1313\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1314\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6 Prepare a DataLoader\n",
        "\n",
        "Now we've got a dataset ready to go.\n",
        "\n",
        "The next step is to prepare it with a [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) or `DataLoader` for short.\n",
        "The `DataLoader` does what you think it might do.\n",
        "It helps load data into a model, both for training and for inference.\n",
        "It turns a large `Dataset` into a Python iterable of smaller chunks.\n",
        "These smaller chunks are called **batches** or **mini-batches** and can be set by the `batch_size` parameter.\n",
        "\n",
        "*Why do this?*\n",
        "\n",
        "Because it's more computationally efficient.\n",
        "In an ideal world you could do the forward pass and backward pass across all of your data at once.\n",
        "But once you start using really large datasets, unless you've got infinite computing power, it's easier to break them up into batches.\n",
        "\n",
        "There are also motivations related to how the model are optimized using algorithms such as stochastic gradient descent\n",
        "\n",
        "\n",
        "*What's a good batch size?*\n",
        "\n",
        "It largely depends on the memory available on the GPU.\n",
        "But since this is a value you can set (a **hyperparameter**) you can try all different kinds of values, though generally powers of 2 are used most often (e.g. 32, 64, 128, 256, 512).\n",
        "\n",
        "![an example of what a batched dataset looks like](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/03-batching-fashionmnist.png)\n",
        "*Batching FashionMNIST with a batch size of 32 and shuffle turned on. A similar batching process will occur for other datasets but will differ depending on the batch size.*\n"
      ],
      "metadata": {
        "id": "tK9-_rZIT_Vi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch's `torch.utils.data.DataLoader` wraps an iterable around a `Dataset` object to enable easy access to the samples and gives us the following functionalities:\n",
        "- Data batching\n",
        "- Data shuffling\n",
        "- Parallel data loading using multiprocessing workers. Meaning that while the GPU is performing some computation on a batch, in parallel you can load the next batch.\n",
        "\n",
        "In other words, `DataLoader` is an iterable that abstracts this complexity for us in an easy API.\n",
        "\n",
        "Let's create `DataLoader`'s for our training and test sets."
      ],
      "metadata": {
        "id": "4tsN28-aU5YS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup training data\n",
        "train_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "# Setup test data\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "eRHCT_xOao78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Setup the batch size hyperparameter\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Turn datasets into iterables (batches)\n",
        "train_dataloader = DataLoader(train_data, # dataset to turn into iterable\n",
        "    batch_size=BATCH_SIZE, # how many samples per batch?\n",
        "    shuffle=True # shuffle data every epoch?\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(test_data,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False # don't necessarily have to shuffle the testing data\n",
        ")\n",
        "\n",
        "# Let's check out what we've created\n",
        "print(f\"Dataloaders: {train_dataloader, test_dataloader}\")\n",
        "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
        "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")"
      ],
      "metadata": {
        "id": "PBaj-9MOVnSp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26d5b87e-a957-4350-ed07-fc5692cb5721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x7a9d9cb19b50>, <torch.utils.data.dataloader.DataLoader object at 0x7a9d9cb18d10>)\n",
            "Length of train dataloader: 1875 batches of 32\n",
            "Length of test dataloader: 313 batches of 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out what's inside the training dataloader\n",
        "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
        "train_features_batch.shape, train_labels_batch.shape"
      ],
      "metadata": {
        "id": "FGOpYPEOVwJ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feb783e1-9cb6-4672-dc1c-ccc368dc9da5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 1, 28, 28]), torch.Size([32]))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we can see that the data remains unchanged by checking a single sample."
      ],
      "metadata": {
        "id": "lauqbMvIV1If"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show a sample\n",
        "torch.manual_seed(42)\n",
        "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
        "print(random_idx)\n",
        "img, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
        "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.title(class_names[label])\n",
        "plt.axis(\"Off\");\n",
        "print(f\"Image size: {img.shape}\")\n",
        "print(f\"Label: {label}, label size: {label.shape}\")"
      ],
      "metadata": {
        "id": "g0S8-STrV1z8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "outputId": "36b61110-ef58-4a7d-99a6-93351b6f4087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "Image size: torch.Size([1, 28, 28])\n",
            "Label: 0, label size: torch.Size([])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are other parameters that can be passed to a DataLoader constructore:\n",
        "- `num_workers`: how many subprocesses to use for data loading. 0 means that the data will be loaded in the main process. (default: 0)\n",
        "- `pin_memory`: If True, the data loader will copy Tensors into device/CUDA pinned memory before returning them. If your data elements are a custom type, or your collate_fn returns a batch that is a custom type, see the example below.\n",
        "\n",
        "For a full list of DataLoader's arguments check the [documentation](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)."
      ],
      "metadata": {
        "id": "dYHOgrt8WfnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from tqdm.notebook import tqdm as tqdm   # just a progress bar\n",
        "import time\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 8\n",
        "\n",
        "train_dataloader = DataLoader(train_data,\n",
        "                       batch_size=BATCH_SIZE,    # number of elements in each batch\n",
        "                       shuffle=True,    # shuffle the dataset\n",
        "                       num_workers=NUM_WORKERS,   # number of workers, i.e. batches to prefetch\n",
        "                       pin_memory=True  # return memory-pinned tensors, see below for an explanation!\n",
        "                       )\n",
        "\n",
        "# 60000 iterations\n",
        "for sample in tqdm(train_data):\n",
        "  pass\n",
        "\n",
        "# 60000/32 iterations\n",
        "for batch in tqdm(train_dataloader):  # there is some overhead when using multiple workers!\n",
        "  # time.sleep(0.1)\n",
        "  pass"
      ],
      "metadata": {
        "id": "ERWkXKFCWgGW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "d50cd371d08244248602eca6b3071b50",
            "5d0b7926bcff48079ec2a62d78e74cf5",
            "02c163309c68401d977ce2b2cca11b69",
            "29dff4adfed04f07b290c45cc9d84c0c",
            "4726372f4cc143cda8988a2a5391aaae",
            "1eaea5e11a8941f8847fe6790e470cb3",
            "8c2be73bb0644a279a1f753e03d21b4f",
            "420f082729194cfa83ea11545150d67f",
            "3072a5aaec28422aa948287a74c106f6",
            "0957721cd3eb485c9ac69150cc10ff33",
            "a86f6ac223ff4de29d506becc6974c1c",
            "e3b9d437df324bff9ec396c58fc84dc2",
            "aaa1280e508e452eabe7d9cb164842fb",
            "a71c9629808a4a0491406bfc0419c673",
            "ab88074389eb4835bc3db46666f82600",
            "16907439f3934b11ad1bba59f890241b",
            "1f84b71f10984cf8b743d31414e55a18",
            "04d8568ee5d047dbbd18bde524230fee",
            "193867506c9845e3b9a6dea3c61de494",
            "026f4f0cd7a24e37be7e68ad2292e51e",
            "3aa11bb6911842a884c9d83ecbf76f11",
            "1e523894fdcc4e3a9c9dd452fba73b6d"
          ]
        },
        "outputId": "d2c94b90-cc39-4635-9bca-c59841e1d00a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/60000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d50cd371d08244248602eca6b3071b50"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1875 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3b9d437df324bff9ec396c58fc84dc2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1 Notes\n",
        "If you the dataset does not return a dictionary or some other form of regular structure from the dataset, you must manually specify *how* to put the samples together to form a batch. This can be done with the `collate_fn` parameter of the `DataLoader`.\n",
        "\n",
        "Please read these [docs](https://pytorch.org/docs/stable/data.html#loading-batched-and-non-batched-data) to understand the default behavior of `collate_fn` and how you can define custom `collate_fn` functions.\n",
        "\n",
        "-----\n",
        "\n",
        "The DataLoader is just an iterator, it can't be directly indexed!"
      ],
      "metadata": {
        "id": "6z6OUwtPYyk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  train_dataloader[0]\n",
        "except Exception as e:\n",
        "  print('Error:', e)"
      ],
      "metadata": {
        "id": "2jDB6zm1ZNhM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7bec3d1-517a-4224-da43-c48795161a69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: 'DataLoader' object is not subscriptable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7 Custom datasets\n",
        "\n",
        "Although PyTorch offers a few pre-loaded datasets that can be used in just one line of code, most of the times we have to create a **custom dataset** using our own data.\n",
        "\n",
        "\n",
        "A **custom dataset** is a collection of data relating to a specific problem you're working on.\n",
        "In essence, a **custom dataset** can be comprised of almost anything.\n",
        "For example, if we were building a food image classification app like [Nutrify](https://nutrify.app), our custom dataset might be images of food.\n",
        "\n",
        "Or if we were trying to build a model to classify whether or not a text-based review on a website was positive or negative, our custom dataset might be examples of existing customer reviews and their ratings.\n",
        "\n",
        "Or if we were trying to build a sound classification app, our custom dataset might be sound samples alongside their sample labels.\n",
        "\n",
        "Or if we were trying to build a recommendation system for customers purchasing things on our website, our custom dataset might be examples of products other people have bought.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/04-pytorch-domain-libraries.png\" alt=\"different pytorch domain libraries can be used for specific PyTorch problems\" width=1000/>\n",
        "\n",
        "\n",
        "We can create a custom dataset by extending (subclassing) the abstract `torch.utils.data.Dataset` class.\n",
        "\n"
      ],
      "metadata": {
        "id": "NjG5MuLZnHBs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.1 Creating a Dataset subclass\n",
        "\n",
        "*What is [`torch.utils.data.Dataset`](https://pytorch.org/docs/stable/data.html?highlight=dataset#torch.utils.data.Dataset)?*\n",
        "\n",
        "It is an abstract class representing a dataset. Your custom dataset should inherit `Dataset` and override the following methods:\n",
        "\n",
        "- `__init__`: The `__init__` function is run once when instantiating the Dataset object. We initialize the directory containing the images, the annotations file, and both transforms (covered in more detail in the next section).\n",
        "- `__len__`: The `__len__` function returns the number of samples in our dataset.\n",
        "- `__getitem__`: The `__getitem__` function loads and returns a sample from the dataset at the given index idx. Based on the index, it identifies the image's location on disk, converts that to a tensor using read_image, retrieves the corresponding label from the csv data in self.img_labels, calls the transform functions on them (if applicable), and returns the tensor image and corresponding label in a tuple.\n",
        "\n",
        "Let's see this in practice with a toy dataset:"
      ],
      "metadata": {
        "id": "yxTNInVQbWJZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HclJRK7QdOZM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a77552c0-a9f4-4e7f-ad58-abfe8c312ddf"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ToyDataset(Dataset): #our ToyDataset class inherits from the Dataset class\n",
        "\n",
        "  def __init__(self, n_points: int = 20, noise: float = .1):\n",
        "    super().__init__()  # In python 3 this is enough\n",
        "    self.n_points = n_points\n",
        "    # these two lines pre-load the entire dataset in memory\n",
        "    self.x = torch.linspace(-1, 1, n_points)\n",
        "    self.y = self.x ** 3 + noise * torch.randn(n_points)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_points\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return {\n",
        "        'x': self.x[idx],\n",
        "        'y': self.y[idx]\n",
        "    }\n",
        "\n",
        "toydataset = ToyDataset(20, noise=.1)\n",
        "toydataset[5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'x': tensor(-0.4737), 'y': tensor(-0.0408)}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZRoEO92fefK"
      },
      "source": [
        "In this case the dataset is composed of simple pairs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-jhx5AUvQ2E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca12877c-88ef-45ee-d0e7-61bbda2ef20f"
      },
      "source": [
        "toydataset[2]\n",
        "\n",
        "#Do you remember how to access the scalar number from a Tensor of rank 0?"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'x': tensor(-0.7895), 'y': tensor(-0.5766)}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "toydataset[2][\"x\"].item()"
      ],
      "metadata": {
        "id": "-UlVOjoJbPKw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eba3273f-de2d-4126-bfdf-16cec8ef6d18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.7894736528396606"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's visualize the data. We are going to use Plotly, but we could also do it with Matplotlib"
      ],
      "metadata": {
        "id": "qrOgmv4YcBNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "toydataset.x.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwNszyAniEFR",
        "outputId": "223c7db8-fe51-4c60-b4b6-2f7df7909bea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.        , -0.8947368 , -0.78947365, -0.68421054, -0.57894737,\n",
              "       -0.4736842 , -0.36842105, -0.2631579 , -0.15789473, -0.05263157,\n",
              "        0.05263157,  0.15789473,  0.2631579 ,  0.36842105,  0.4736842 ,\n",
              "        0.57894737,  0.68421054,  0.78947365,  0.8947368 ,  1.        ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6vM4yKRfZEm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "35035499-a18d-45f6-a903-13f40fb91024"
      },
      "source": [
        "import plotly.express as px\n",
        "fig = px.scatter(x=toydataset.x, y=toydataset.y)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"d041308a-eaba-4993-bcae-81a28677759c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d041308a-eaba-4993-bcae-81a28677759c\")) {                    Plotly.newPlot(                        \"d041308a-eaba-4993-bcae-81a28677759c\",                        [{\"hovertemplate\":\"x=%{x}\\u003cbr\\u003ey=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[-1.0,-0.8947368,-0.78947365,-0.68421054,-0.57894737,-0.4736842,-0.36842105,-0.2631579,-0.15789473,-0.052631572,0.052631572,0.15789473,0.2631579,0.36842105,0.4736842,0.57894737,0.68421054,0.78947365,0.8947368,1.0],\"xaxis\":\"x\",\"y\":[-1.0102335,-0.7762004,-0.44434854,-0.24769138,-0.03051065,-0.040809624,0.00759317,-0.054315224,-0.009995472,0.0071796826,0.082011096,0.15198383,0.12153297,-0.018657807,0.16996506,0.21580693,0.3156436,0.34870207,0.65963244,0.95747167],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d041308a-eaba-4993-bcae-81a28677759c');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NS0j3M_pgk8s"
      },
      "source": [
        "> **NOTE**\n",
        ">\n",
        "> Small Python reminder. Every object that implements the `__getitem__` method follows the [iterator procotol](https://www.python.org/dev/peps/pep-0234/#python-api-specification). It means that you can **iterate** the dataset:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMdwLEFDhZCu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "39496ff7a4b4485fb37e68a2d1cb75f8",
            "7c73906b12fb4dd885efe8f59f5632d0",
            "3178992e04a94e5495db1b463ea69f39",
            "eb84202bf0c947ff8b044ed42966ddcf",
            "b4c500c98fab4fa5b3a51247f22ea634",
            "7970871adedc4f3da6367f38a71ad3e8",
            "510b5564fe5647189b527c0e7836ba1d",
            "b7037cbebc4c4157a45f42be2337b0f7",
            "eb8abee4d31849b485d594ad21716e3e",
            "86029d368a2c4cccb81524914d1aca77",
            "11f467df100b431fa05a5f4c29a7a406"
          ]
        },
        "outputId": "868caf37-538c-40e7-8aee-7ec24d647007"
      },
      "source": [
        "from tqdm.notebook import tqdm as tqdm   # just a progress bar\n",
        "import time\n",
        "\n",
        "for sample in tqdm(toydataset):  # wrap the iterable in tqdm and you're done\n",
        "  time.sleep(0.1)\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "39496ff7a4b4485fb37e68a2d1cb75f8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GXYYwNTfK7D"
      },
      "source": [
        "In the `ToyDataset` the whole dataset is stored **in memory**, i.e. in attributes of the `ToyDataset` class.\n",
        "This is the fastest and simplest way to implement a dataset, but it is **not always feasible**.\n",
        "What if you must train a neural network on 500GB of images?\n",
        "The whole dataset does not fit in memory!\n",
        "\n",
        "For the same reason, using a single file to store the whole dataset does not scale with the dataset size.\n",
        "*Obviously, this depends on the file format used, e.g. it is perfectly fine if we are dealing with `HDF5` files*\n",
        "\n",
        "The `Dataset` abstraction is particularly useful when implementing *lazy loading* policies, that is, when you load each item **only when you need it**.\n",
        "You can even apply some preprocessing on the fly, to each item.\n",
        "\n",
        "One example of how it can be done:\n",
        "\n",
        "```python\n",
        "class LazyDataset(Dataset):\n",
        "\n",
        "  def __init__(self, file_paths: Sequence[Path]):\n",
        "    super().__init__()  \n",
        "    self.file_paths = file_paths\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.file_paths)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    sample_path = self.file_paths[idx]\n",
        "\n",
        "    # -> Load sample_path in memory\n",
        "    # -> Perform some lightweight preprocessing\n",
        "    # -> Generate (sample_input, sample_output)\n",
        "\n",
        "    return {\n",
        "        'x': sample_input,\n",
        "        'y': sample_output\n",
        "    }\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils import Dataset\n",
        "class LazyDataset(Dataset):\n",
        "\n",
        "  def __init__(self, file_paths):\n",
        "    super().__init__()\n",
        "    self.file_paths = file_paths   # \"drive/MyDrive/\"\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.file_paths)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    x = np.load(self.file_paths[index] + \"x.npy\")\n",
        "    y = np.load(self.file_paths[index] + \"y.npy\")\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "qt5G-_TvmC1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P79iR6q0gIzw"
      },
      "source": [
        "**NOTE**\n",
        "\n",
        "The dataset can return any type of object, you are *not* forced to return a dictionary of tensors:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDg1ggjdiMA4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "771eee3b-ff34-4784-d017-63b5fd088911"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class AnotherDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.myitems = torch.arange(100)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.myitems)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return f'Sample{idx}', self.myitems[idx], None, 3.5\n",
        "\n",
        "dataset = AnotherDataset()\n",
        "dataset[5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Sample5', tensor(5), None, 3.5)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[5][1].item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8F8mhBRjxk8",
        "outputId": "4d0a1654-0e97-409e-a2a5-d30f386ab4d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOwlr_u2iLh6"
      },
      "source": [
        "\n",
        "However, it is often useful to return a dictionary of tensors.\n",
        "\n",
        "⚠️ Do *not* return tensors that are stored on the GPU memory, as it [causes problems](https://pytorch.org/docs/stable/data.html#multi-process-data-loading) with the multiprocessing behavior of the DataLoader. We'll see memory pinning as a preferred way, further below.\n",
        "\n",
        "Returning a dictionary of tensors will:\n",
        "\n",
        "- Make your code more readable\n",
        "- Ease the batch creation process: you may use the `DataLoader` default `collate_fn` (we'll see this in a second)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2 Importing data from Google Drive\n",
        "Cool, we created a custom dataset. But that example is not particularly useful, since we actually create the data within the Dataset object. Most commonly, we already have our data hosted somewhere.\n",
        "\n",
        "Since we are working with Colab, it is quite convenient to import data from our Google Drive. However, if you were working on your computer the data may be located in some folder on your hard drive.\n",
        "\n",
        "For this exercise, you can copy the data from this [folder](https://drive.google.com/drive/folders/1cIQg6GwSFRZRQ1PyFv6pRdeKxfBCr18F?usp=drive_link).\n",
        "It is a very small (51 image) sample from the [IDDA dataset](https://idda-dataset.github.io/home/).\n",
        "Once you have downloaded this data, put it in your Google Drive.\n",
        "\n",
        "\n",
        "In Colab, you can mount your drive as follows\n",
        "```\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "```"
      ],
      "metadata": {
        "id": "d9Dw39F4NpPk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's try to mount the drive"
      ],
      "metadata": {
        "id": "dewasPX1gpwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "qtkb4SzLY9WS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7ed58d8-c74e-4d88-d089-da1ac892100e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And let's see what is in our drive and if we can find our data."
      ],
      "metadata": {
        "id": "QYs-Yq2rg-S7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"1)\")\n",
        "!pwd #prints the path\n",
        "print()\n",
        "\n",
        "print(f\"2)\")\n",
        "!ls #lists the folders and files at this level\n",
        "print()\n",
        "\n",
        "print(\"3)\")\n",
        "!ls drive/MyDrive/Old\\ stuff #This is where the data is located\n",
        "print()\n",
        "\n",
        "print(\"4)\")\n",
        "!ls drive/MyDrive/Datasets/IDDA_examples/RGB #Here are the images\n",
        "print()\n",
        "\n",
        "print(\"5)\")\n",
        "!ls drive/MyDrive/Datasets/IDDA_examples/SemanticRGB # here are the labels"
      ],
      "metadata": {
        "id": "PeSJBWGwhDlo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db60ac2d-5148-4a74-c5a9-8310104e0365"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1)\n",
            "/content\n",
            "\n",
            "2)\n",
            "data  drive  sample_data\n",
            "\n",
            "3)\n",
            " Ballo.pdf\t\t\t        IMG_8459.JPG\n",
            " Basi_di_dati.pdf\t\t        IMG_8484.JPG\n",
            "'Definizioni 1.gdoc'\t\t        IMG_8489.JPG\n",
            "'Diretta Halloween DJ set.mp4'\t        IMG_8498.JPG\n",
            "'Disegno senza titolo.gdraw'\t        IMG_8509.JPG\n",
            " family.jpg\t\t\t        IMG_8510.JPG\n",
            "'Fanta basket_1.pdf'\t\t        IMG_8515.JPG\n",
            "'Fanta basket.pdf'\t\t        IMG.pdf\n",
            " Fantabasket.pdf\t\t        immagine.png\n",
            " Fly.mp3\t\t\t       'Link Modulistica ASL.odt (Recuperato).gdoc'\n",
            "'Foglio di lavoro senza nome.gsheet'   'Relazione velocità di reazione.docx'\n",
            "'Foto da aless marinai'\t\t       'Relazione velocità di reazione.docx.gdoc'\n",
            "'Foto da aless marinai2'\t        Screenshot_2018-09-05-22-10-06.png\n",
            "'fyd-nktz-sfh - 22 gen 2022.gjam'       TOp.pdf\n",
            "'fyd-nktz-sfh - 22 gen 2022.pdf'       'Uffizi-Ambasciatori del Verde    fin.doc'\n",
            "'ifu-uvab-yxp - 10 dic 2021 (1).gjam'  'Untitled 1.odt'\n",
            "'ifu-uvab-yxp - 10 dic 2021 (1).pdf'    video-2015-01-23-21-32-45.mp4\n",
            "'ifu-uvab-yxp - 10 dic 2021.gjam'       video-2015-01-24-07-20-16.mp4\n",
            "'ifu-uvab-yxp - 10 dic 2021.pdf'        video-2015-01-24-07-47-40.mp4\n",
            "'IMG_20180525_191056 (1).jpg'\t        video-2015-01-24-07-50-52.mp4\n",
            " IMG_20180525_191056.jpg\t        video-2015-01-24-07-55-12.mp4\n",
            " IMG_20180601_114609.jpg\t        video-2015-01-24-07-58-48.mp4\n",
            " IMG_20190203_124134.jpg\t        video-2015-01-24-13-55-44.mp4\n",
            " IMG-20190203-WA0014.jpg\t        video-2015-01-25-09-52-39.mp4\n",
            " IMG_2098.MOV\t\t\t       'Video da parte di aless marinai'\n",
            " IMG_8455.JPG\t\t\t       'Video da parte di aless marinai (1)'\n",
            "\n",
            "4)\n",
            "ls: cannot access 'drive/MyDrive/Datasets/IDDA_examples/RGB': No such file or directory\n",
            "\n",
            "5)\n",
            "ls: cannot access 'drive/MyDrive/Datasets/IDDA_examples/SemanticRGB': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's read the paths of the images present in the folder and put them in a list.\n",
        "We can do this in different ways. For example, we can use the [os](https://docs.python.org/3/library/os.html) package or the [pathlib](https://docs.python.org/3/library/pathlib.html) package"
      ],
      "metadata": {
        "id": "xW7mv9YtiSe_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Using pathlib and glob\n",
        "from pathlib import Path\n",
        "\n",
        "image_path = Path(\"drive/MyDrive/Datasets/IDDA_examples/\")\n",
        "image_path_list = list(image_path.glob(\"RGB/*.jpg\"))\n",
        "print(image_path_list)\n"
      ],
      "metadata": {
        "id": "b1nLkVhWZNnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Using os\n",
        "import os\n",
        "\n",
        "image_path = \"drive/MyDrive/Datasets/IDDA_examples/\"\n",
        "for dirpath, dirnames, filenames in os.walk(image_path+\"/RGB\"):\n",
        "  print(filenames)\n",
        "print()\n",
        "\n",
        "image_paths = os.listdir(image_path+\"/RGB\")\n",
        "print(image_paths)\n",
        "\n",
        "#Question: how can we exclude from the list the files that are not images?"
      ],
      "metadata": {
        "id": "saQobM6K8cq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Soluzione\n",
        "import os\n",
        "\n",
        "image_path = \"drive/MyDrive/Datasets/IDDA_examples/\"\n",
        "image_paths = [x for x in os.listdir(image_path+\"/RGB\") if x.endswith(\".jpg\")]\n",
        "print(image_paths)"
      ],
      "metadata": {
        "id": "PsajMhXC_XuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let's create our custom dataset with the data that we have copied to our Drive. We will use the lazy approach, storing in the class not directly the data, but rather the paths to where it is stored."
      ],
      "metadata": {
        "id": "NoihVKUuvjxE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.3 Example: Custom Dataset from our Google Drive data"
      ],
      "metadata": {
        "id": "xAA0SagCiR_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "class IDDADataset(Dataset):\n",
        "\n",
        "  def __init__(self, data_path):\n",
        "    super().__init__()\n",
        "    self.image_path = data_path+\"/RGB/\"\n",
        "    self.label_path = data_path+\"/SemanticRGB/\"\n",
        "    self.images_list = [x for x in os.listdir(self.image_path) if x.endswith(\".jpg\")]\n",
        "    self.labels_list = [x for x in os.listdir(self.label_path) if x.endswith(\".jpg\")]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.file_paths)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    x_path = self.images_list[idx]\n",
        "    y_path = self.labels_list[idx]\n",
        "\n",
        "    # -> Load sample_path in memory\n",
        "    x = np.array(Image.open(self.image_path+x_path))\n",
        "    y = np.array(Image.open(self.label_path+y_path))\n",
        "\n",
        "    # -> Generate (sample_input, sample_output)\n",
        "    return {\n",
        "        'x': x,\n",
        "        'y': y\n",
        "    }\n",
        "\n",
        "idda_dataset = IDDADataset(\"drive/MyDrive/Datasets/IDDA_examples/\")"
      ],
      "metadata": {
        "id": "nk_jAUbsZpOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try and visualize a sample from our Custom Dataset"
      ],
      "metadata": {
        "id": "EUgMRJb2ir1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idda_dataset = IDDADataset(\"drive/MyDrive/Datasets/IDDA_examples/\")\n",
        "N = 5\n",
        "img = idda_dataset[N][\"x\"]\n",
        "label = idda_dataset[N][\"y\"]\n",
        "print(img.shape)\n",
        "print(label.shape)\n",
        "\n",
        "\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "\n",
        "figure.add_subplot(1, 2, 1)\n",
        "plt.title(\"Immagine\")\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(img)\n",
        "\n",
        "figure.add_subplot(1, 2, 2)\n",
        "plt.title(\"Ground truth\")\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(label)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PWFX-Es6BifR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.4 DatasetFolder and ImageFolder\n",
        "What we have seen in the previous section is a very general way for creating a custom dataset from our own data.\n",
        "It turns out that for a multiclass classification task, PyTorch already provides some utilities to create a dataset giving as parameter the folders where the data is stored.\n",
        "\n",
        "[`DatasetFolder`](https://pytorch.org/vision/stable/generated/torchvision.datasets.DatasetFolder.html#torchvision.datasets.DatasetFolder)is a dataloader  that expects a certain directory structure can be customized by overriding the `find_classes()` method.\n",
        "\n",
        "This is the kind of directory structure that it expects.\n",
        "```\n",
        "directory/\n",
        "├── class_x\n",
        "│   ├── xxx.ext\n",
        "│   ├── xxy.ext\n",
        "│   └── ...\n",
        "│       └── xxz.ext\n",
        "└── class_y\n",
        "    ├── 123.ext\n",
        "    ├── nsdf3.ext\n",
        "    └── ...\n",
        "    └── asd932_.ext\n",
        "```\n",
        "As you can see, the data is divided in folders, each folder corresponding to a class. For the custom dataset that we used, we could not use this method since it is not data formatted for a classification task.\n",
        "\n",
        "The [`ImageFolder`](https://pytorch.org/vision/stable/generated/torchvision.datasets.ImageFolder.html#torchvision.datasets.ImageFolder) operates similarly, but it is specific for images.\n",
        "It expects the following directory structure\n",
        "\n",
        "```\n",
        "root/dog/xxx.png\n",
        "root/dog/xxy.png\n",
        "root/dog/[...]/xxz.png\n",
        "\n",
        "root/cat/123.png\n",
        "root/cat/nsdf3.png\n",
        "root/cat/[...]/asd932_.png\n"
      ],
      "metadata": {
        "id": "D0ju7BKfjMKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8 📓 Exercise: Create a Custom Dataset\n",
        "\n",
        "Try to put in practice the things we have see so far.\n",
        "First things first we need some data.\n",
        "And like any good cooking show, some data has already been prepared for us.\n",
        "\n",
        "The data we're going to be using is a subset of the [Food101 dataset](https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/).\n",
        "Food101 is popular computer vision benchmark as it contains 1000 images of 101 different kinds of foods, totaling 101,000 images (75,750 train and 25,250 test).\n",
        "\n",
        "Instead of 101 food classes though, we're going to start with 3: pizza, steak and sushi.\n",
        "And instead of 1,000 images per class, we're going to start with a random 10% (start small, increase when necessary).\n",
        "Here you can [download the data](https://drive.google.com/drive/folders/1JaYA4aOWeCLhd-jYjVHgOiPcnSu0JR96?usp=sharing) and copy it to your Google Drive.\n",
        "\n",
        "> **Note:** This dataset has been pre-formatted for a multi-class classification task and has the following directory structure\n",
        "```\n",
        "pizza_steak_sushi/ <- overall dataset folder\n",
        "    train/ <- training images\n",
        "        pizza/ <- class name as folder name\n",
        "            image01.jpeg\n",
        "            image02.jpeg\n",
        "            ...\n",
        "        steak/\n",
        "            image24.jpeg\n",
        "            image25.jpeg\n",
        "            ...\n",
        "        sushi/\n",
        "            image37.jpeg\n",
        "            ...\n",
        "    test/ <- testing images\n",
        "        pizza/\n",
        "            image101.jpeg\n",
        "            image102.jpeg\n",
        "            ...\n",
        "        steak/\n",
        "            image154.jpeg\n",
        "            image155.jpeg\n",
        "            ...\n",
        "        sushi/\n",
        "            image167.jpeg\n",
        "            ...\n",
        "```\n",
        "So you could try both to create a Custom Dataset as we have seen, or also try to use the ImageFolder method (which we have not tried).\n",
        "\n",
        "What you should do:\n",
        "1. load the data and mount your drive\n",
        "2. create a dataset\n",
        "3. check the dataset and visualize some data samples\n",
        "4. create a dataloader\n"
      ],
      "metadata": {
        "id": "7hDyKzYImCKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here"
      ],
      "metadata": {
        "id": "N2L143a5mY6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9 Data Transforms\n",
        "Data does not always come in its final processed form that is required for training machine learning algorithms. We use transforms to perform some manipulation of the data and make it suitable for training.\n",
        "\n",
        "For example, the FashionMNIST features are in PIL Image format, and the labels are integers. For training, we need the features as normalized tensors, and the labels as one-hot encoded tensors.\n",
        "\n",
        "*How can we do this?*\n",
        "```\n",
        "train_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "```\n",
        "We can use transforms. Let's see an example and then comment it."
      ],
      "metadata": {
        "id": "Fn19TL-4oJtU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "\n",
        "ds = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
        ")"
      ],
      "metadata": {
        "id": "AuoXzU1GwTZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ToTensor\n",
        "[`ToTensor()`](https://pytorch.org/tutorials/beginner/basics/transforms_tutorial.html) is a PyTorch builtin transformation that converts a PIL image or NumPy `ndarray` into a `FloatTensor`. and scales the image's pixel intensity values in the range [0., 1.]"
      ],
      "metadata": {
        "id": "hx-hbmCWvjRv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Lambda Transforms\n",
        "Lambda transforms apply any user-defined lambda function.\n",
        "\n",
        "For example, we can define a function to turn the integer into a one-hot encoded tensor. It first creates a zero tensor of size 10 (the number of labels in our dataset) and calls `scatter_` which assigns a value=1 on the index as given by the label `y`."
      ],
      "metadata": {
        "id": "AU3h6JDov-tB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's check a sample from our dataset"
      ],
      "metadata": {
        "id": "T_mBsIYEwbrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds[0]"
      ],
      "metadata": {
        "id": "sJgsIDUxweyF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e05cdcdb-80f5-46f4-f043-e4d21c3f03a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
              "           0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0039, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
              "           0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
              "           0.0157, 0.0000, 0.0000, 0.0118],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
              "           0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0471, 0.0392, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
              "           0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
              "           0.3020, 0.5098, 0.2824, 0.0588],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
              "           0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
              "           0.5529, 0.3451, 0.6745, 0.2588],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
              "           0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
              "           0.4824, 0.7686, 0.8980, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
              "           0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
              "           0.8745, 0.9608, 0.6784, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
              "           0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
              "           0.8627, 0.9529, 0.7922, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
              "           0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
              "           0.8863, 0.7725, 0.8196, 0.2039],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
              "           0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
              "           0.9608, 0.4667, 0.6549, 0.2196],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
              "           0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
              "           0.8510, 0.8196, 0.3608, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
              "           0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
              "           0.8549, 1.0000, 0.3020, 0.0000],\n",
              "          [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
              "           0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
              "           0.8784, 0.9569, 0.6235, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
              "           0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
              "           0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
              "           0.9137, 0.9333, 0.8431, 0.0000],\n",
              "          [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
              "           0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
              "           0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
              "           0.8627, 0.9098, 0.9647, 0.0000],\n",
              "          [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
              "           0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
              "           0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
              "           0.8706, 0.8941, 0.8824, 0.0000],\n",
              "          [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
              "           0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
              "           0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
              "           0.8745, 0.8784, 0.8980, 0.1137],\n",
              "          [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
              "           0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
              "           0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
              "           0.8627, 0.8667, 0.9020, 0.2627],\n",
              "          [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
              "           0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
              "           0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
              "           0.7098, 0.8039, 0.8078, 0.4510],\n",
              "          [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
              "           0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
              "           0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
              "           0.6549, 0.6941, 0.8235, 0.3608],\n",
              "          [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
              "           0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
              "           0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
              "           0.7529, 0.8471, 0.6667, 0.0000],\n",
              "          [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
              "           0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
              "           0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
              "           0.3882, 0.2275, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
              "           0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]))"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clearly, this works only when we load an existing dataset from PyTorch,\n",
        "When we create a custom dataset, we should apply the transformation to the data ourselves.\n",
        "\n",
        "When working with images, such as in the examples we have seen so far, we can rely on several existing transformations from the `torchvision.transforms` module.\n",
        "`torchvision.transforms` contains many pre-built methods for formatting images, turning them into tensors and even manipulating them for **data augmentation** (the practice of altering data to make it harder for a model to learn, we'll see this later on) purposes.\n",
        "\n",
        "To get experience with `torchvision.transforms`, let's write a series of transform steps that:\n",
        "1. Resize the images using [`transforms.Resize()`](https://pytorch.org/vision/stable/generated/torchvision.transforms.Resize.html#torchvision.transforms.Resize) (from about 512x512 to 64x64, the same shape as the images on the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/)).\n",
        "2. Flip our images randomly on the horizontal using [`transforms.RandomHorizontalFlip()`](https://pytorch.org/vision/stable/generated/torchvision.transforms.RandomHorizontalFlip.html#torchvision.transforms.RandomHorizontalFlip) (this could be considered a form of data augmentation because it will artificially change our image data).\n",
        "3. Turn our images from a PIL image to a PyTorch tensor using [`transforms.ToTensor()`](https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html#torchvision.transforms.ToTensor).\n",
        "\n",
        "We can compile all of these steps using [`torchvision.transforms.Compose()`](https://pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose)."
      ],
      "metadata": {
        "id": "CsYPbrNqw835"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# Write transform for image\n",
        "data_transform = transforms.Compose([\n",
        "    # Resize the images to 64x64\n",
        "    transforms.Resize(size=(64, 64)),\n",
        "    # Flip the images randomly on the horizontal\n",
        "    transforms.RandomHorizontalFlip(p=0.5), # p = probability of flip, 0.5 = 50% chance\n",
        "    # Turn the image into a torch.Tensor\n",
        "    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0\n",
        "])"
      ],
      "metadata": {
        "id": "cWx72eBUyMVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got a composition of transforms, let's write a function to try them out on various images."
      ],
      "metadata": {
        "id": "xvHJbpGQyYDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=data_transform,\n",
        "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
        ")\n",
        "\n",
        "img, label = ds[0]\n",
        "plt.imshow(img.squeeze(), cmap=\"gray\")"
      ],
      "metadata": {
        "id": "q7pZvPBOyvVw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "ba381f85-1a3e-4309-ecd1-c14c8e990d04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7a9d96d04ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's try to use this same transform with our custom dataset"
      ],
      "metadata": {
        "id": "Vy7Cewx9zIs_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IDDADataset(Dataset):\n",
        "\n",
        "  def __init__(self, data_path, data_transform, target_transform): #we pass the transform as argument\n",
        "    super().__init__()\n",
        "    self.image_path = data_path+\"/RGB/\"\n",
        "    self.label_path = data_path+\"/SemanticRGB/\"\n",
        "    self.images_list = [x for x in os.listdir(self.image_path) if x.endswith(\".jpg\")]\n",
        "    self.labels_list = [x for x in os.listdir(self.label_path) if x.endswith(\".jpg\")]\n",
        "    self.data_transform = data_transform\n",
        "    self.target_transform = target_transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.file_paths)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    x_path = self.images_list[idx]\n",
        "    y_path = self.labels_list[idx]\n",
        "\n",
        "    # -> Load sample_path in memory\n",
        "    x = self.data_transform(Image.open(self.image_path+x_path))\n",
        "    y = self.target_transform(Image.open(self.label_path+y_path))\n",
        "\n",
        "    # -> Generate (sample_input, sample_output)\n",
        "    return {\n",
        "        'x': x,\n",
        "        'y': y\n",
        "    }\n",
        "\n",
        "\n",
        "idda_dataset = IDDADataset(\"drive/MyDrive/Datasets/IDDA_examples/\", data_transform, transforms.ToTensor())\n",
        "N = 5\n",
        "img = idda_dataset[N][\"x\"]\n",
        "label = idda_dataset[N][\"y\"]\n",
        "print(img.shape)\n",
        "print(label.shape)\n",
        "\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "figure.add_subplot(1, 2, 1)\n",
        "plt.title(\"Immagine\")\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(torch.permute(img, (1,2,0)))\n",
        "figure.add_subplot(1, 2, 2)\n",
        "plt.title(\"Ground truth\")\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(torch.permute(label, (1,2,0)))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oyng3ZQgzUG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYYP8rCj2-Ae"
      },
      "source": [
        "## 10 🛑 Optional: Memory pinning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRqZeY_A1Ink"
      },
      "source": [
        "Pytorch tensors support [memory pinning](https://devblogs.nvidia.com/how-optimize-data-transfers-cuda-cc/):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1BIKzR36fww"
      },
      "source": [
        "![](https://devblogs.nvidia.com/wp-content/uploads/2012/12/pinned-1024x541.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84rs4T_66ffq"
      },
      "source": [
        "\n",
        "Pinned tensors enable:\n",
        "- **Much faster copies** from CPU to GPU.\n",
        "- **Aynchronous GPU copies**: *while* the tensor is being transferred, the code continues if it doesn't need that tensor! To enable this, just pass an additional **`non_blocking=True`** argument to a `to()` or a `cuda()` call.  (**gpu operations are [asynchronous](https://pytorch.org/docs/stable/notes/cuda.html#asynchronous-execution) by default**)\n",
        "\n",
        "Given a tensor you can manually pin it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF0GVdOq3tnG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70c5828e-f002-4a6f-bd3d-80e00c44b61b"
      },
      "source": [
        "import torch\n",
        "t = torch.rand(100)\n",
        "t.is_pinned()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6p_mlBoh3p-a"
      },
      "source": [
        "# be sure to use a GPU runtime, otherwise there's nothing to pin for!\n",
        "\n",
        "t = t.pin_memory()  # reassigning to t, because pin_memory() is not in-place"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgFj15grDJPl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "343e028b-87c2-4856-c7b6-e52a0c7abf54"
      },
      "source": [
        "t.is_pinned()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nY2UFPT14EkF"
      },
      "source": [
        "Passing `pin_memory=True` to a `DataLoader` will automatically put the fetched data tensors in pinned memory, enabling faster data transfer to CUDA-enabled GPUs.\n",
        "\n",
        "`DataLoader` only knows how to pin the standard types returned by `Dataset`; this includes Tensor, Map and Sequence of Tensors. If you want to pin some custom type, read more [here](https://pytorch.org/docs/stable/data.html#memory-pinning) (tldr: define a `pin_memory()` method on your custom type(s))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gNnoz6U5sMz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "d20e9fab-8141-4bac-e3c7-9814bda0baf1"
      },
      "source": [
        "batch['x'].is_pinned()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'batch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-9e52c1e45c3f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_pinned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'batch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4l1TIvepi6H"
      },
      "source": [
        "### Troubleshooting bottlenecks\n",
        "Make sure the data loading is **not a bottleneck** in your pipeline.\n",
        "Your GPU must not **wait for data**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFEIytCKlMsQ"
      },
      "source": [
        "#### How to check if your data loading is a bottleneck?\n",
        "\n",
        "##### **Check resource usage**\n",
        "\n",
        "Check the GPU (or CPU) usage, if it is ~$100\\%$ it is being fully utilised. This is good!\n",
        "\n",
        "Otherwise you may have a bottleneck somewhere, or your data operations may not be GPU friendly (e.g. small batches).\n",
        "\n",
        "\n",
        "##### **Check data loading speed**\n",
        "\n",
        "Iterate over the `Dataset` or `DataLoader` and check the data loading speed by counting the number of items that are loaded per second. Then compare this to how many items per second are processed by the rest of the pipeline.\n",
        "\n",
        "If you can load more items than you can process in the training loop, it means you _don't_ have a bottleneck in your data loading. The GPU is not waiting for you, good job!\n",
        "\n",
        "You can use the [tqdm](https://github.com/tqdm/tqdm) package to easily check the iteration speed of any iterable with a minimal overhead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PLGSqUenoTz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "eda8c564-c820-4551-fa29-5dac52289da0"
      },
      "source": [
        "# Checking the loading speed\n",
        "from tqdm.notebook import tqdm as tqdm  # just a progress bar\n",
        "\n",
        "toydataset = ToyDataset(20000)\n",
        "toyloader = DataLoader(toydataset,\n",
        "                       batch_size=8,    # number of elements in each batch\n",
        "                       shuffle=True,    # shuffle the dataset\n",
        "                       num_workers=4,   # number of workers, i.e. batches to prefetch\n",
        "                       pin_memory=True  # return memory pinnded tensors\n",
        "                       )\n",
        "for batch in tqdm(toyloader):\n",
        "  pass\n",
        "\n",
        "# Example:\n",
        "# tqdm reports 350.00it/s (iterations per second) for the loader.\n",
        "# tqdm reports 280.12it/s for the training step given the data.\n",
        "# -> data loading is NOT a bottleneck!\n",
        "#\n",
        "# This scenario means your computation time is the primary factor in how long\n",
        "# each iteration takes, and the data loading process is efficient enough to keep\n",
        "# up with the computational demands."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'ToyDataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-e29dcc63f4af>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtqdm\u001b[0m  \u001b[0;31m# just a progress bar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtoydataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mToyDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m toyloader = DataLoader(toydataset,\n\u001b[1;32m      6\u001b[0m                        \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0;31m# number of elements in each batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ToyDataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUhUSCRNoTQb"
      },
      "source": [
        "#### How to fix a bottleneck in the data loading?\n",
        "\n",
        "##### 1) **Use in-memory datasets**\n",
        "If your dataset fits on memory, load the whole dataset in memory.\n",
        "\n",
        "##### 2) **Tune DataLoader parameters**\n",
        "Tune the `num_workers` and `batch_size` parameter of the `DataLoader`, paying attention that the batch size will have a direct impact on the training. A good default for `num_workers` is the number of cores in your CPU.\n",
        "\n",
        "##### 3) **Do not preprocess on the fly**\n",
        "If you need preprocessing for your files, save the preprocessed files to disk.\n",
        "\n",
        "##### 4) **Speed up raw file loading**\n",
        "If even just loading the files from disk is slow, consider changing the way in which the files are stored (e.g. another [format](https://www.h5py.org/) or a [database](https://github.com/google/leveldb))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34YGEYsZyBvS"
      },
      "source": [
        "> **NOTE**\n",
        ">\n",
        "> You can read much more on the `torch.utils.data` package [here](https://pytorch.org/docs/stable/data.html).\n",
        ">\n",
        "> Moreover, keep in mind that the [`torchvision`](https://pytorch.org/vision/stable/index.html) package provides some common datasets and transforms. We'll use it next week!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiCv7axFUEel"
      },
      "source": [
        "## 11 📓 Optional Exercise\n",
        "\n",
        "You want to create a neural network that is able to learn how to recover corrupted images from the [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset. That is, given as input a corrupted image, the model outputs a corresponding uncorrupted version.\n",
        "\n",
        "You are free to choose the type of corruption to apply. Possible examples are: random noise, random black patches, random crop, random reflections, all the previous together.\n",
        "\n",
        "1. Think about the data pipeline this model would require. What should the dataset return?\n",
        "2. Create the `Dataset` and `DataLoader` to implement it.\n",
        "3. Plot the images in a **batch** to ensure you are doing everything right.\n",
        "4. Try to apply various transformations to the data\n",
        "\n",
        "*hint*: you may use [`torchvision.datasets`](https://pytorch.org/vision/stable/datasets.html) and [`torchvision.transforms`](https://pytorch.org/vision/stable/transforms.html)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✏️ your code here"
      ],
      "metadata": {
        "id": "CuCHY0Zb-9pH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}