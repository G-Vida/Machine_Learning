{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/G-Vida/Machine_Learning/blob/main/Copia_di_Esercitazione_WandB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLME: Weights and Biases tutorial"
      ],
      "metadata": {
        "id": "Y3DSP-uANd8V"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7K9ov704a-X"
      },
      "source": [
        "<img src=\"http://wandb.me/logo-im-png\" width=\"300\" alt=\"Weights & Biases\" />\n",
        "\n",
        "<!--- @wandbcode{tables_quickstart} -->\n",
        "\n",
        "\n",
        "# View & analyze model predictions during training\n",
        "\n",
        "This quickstart guide covers how to track, visualize, and compare model predictions over the course of training, using PyTorch on MNIST data.\n",
        "\n",
        "With [W&B Tables](https://docs.wandb.com/datasets-and-predictions):\n",
        "1. Log metrics, images, text, etc. to a `wandb.Table()` during model training or evaluation\n",
        "2. View, sort, filter, group, join, interactively query, and explore these tables\n",
        "3. Compare model predictions or results: dynamically across specific images, hyperparameters/model versions, or time steps.\n",
        "\n",
        "# Examples\n",
        "## Compare predicted scores for specific images\n",
        "\n",
        "[Live example: compare predictions after 1 vs 5 epochs of training →](https://wandb.ai/stacey/table-quickstart/reports/CNN-2-Progress-over-Training-Time--Vmlldzo3NDY5ODU#compare-predictions-after-1-vs-5-epochs)\n",
        "<img src=\"https://i.imgur.com/NMme6Qj.png\" alt=\"1 epoch vs 5 epochs of training\"/>\n",
        "The histograms compare per-class scores between the two models. The top green bar in each histogram represents model \"CNN-2, 1 epoch\" (id 0), which only trained for 1 epoch. The bottom purple bar represents model \"CNN-2, 5 epochs\" (id 1), which trained for 5 epochs. The images are filtered to cases where the models disagree. For example, in the first row, the \"4\" gets high scores across all the possible digits after 1 epoch, but after 5 epochs it scores highest on the correct label and very low on the rest.\n",
        "\n",
        "## Focus on top errors over time\n",
        "[Live example →](https://wandb.ai/stacey/table-quickstart/reports/CNN-2-Progress-over-Training-Time--Vmlldzo3NDY5ODU#top-errors-over-time)\n",
        "\n",
        "See incorrect predictions (filter to rows where \"guess\" != \"truth\") on the full test data. Note that there are 229 wrong guesses after 1 training epoch, but only 98 after 5 epochs.\n",
        "<img src=\"https://i.imgur.com/7g8nodn.png\" alt=\"side by side, 1 vs 5 epochs of training\"/>\n",
        "\n",
        "## Compare model performance and find patterns\n",
        "\n",
        "[See full detail in a live example →](https://wandb.ai/stacey/table-quickstart/reports/CNN-2-Progress-over-Training-Time--Vmlldzo3NDY5ODU#false-positives-grouped-by-guess)\n",
        "\n",
        "Filter out correct answers, then group by the guess to see examples of misclassified images and the underlying distribution of true labels—for two models side-by-side. A model variant with 2X the layer sizes and learning rate is on the left, and the baseline is on the right. Note that the baseline makes slightly more mistakes for each guessed class.\n",
        "<img src=\"https://i.imgur.com/i5PP9AE.png\" alt=\"grouped errors for baseline vs double variant\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LY6olkzJ4a-Y"
      },
      "source": [
        "# Sign up or login\n",
        "\n",
        "[Sign up or login](https://wandb.ai/login) to W&B to see and interact with your experiments in the browser.\n",
        "\n",
        "In this example we're using Google Colab as a convenient hosted environment, but you can run your own training scripts from anywhere and visualize metrics with W&B's experiment tracking tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKn6q3sY4a-p"
      },
      "outputs": [],
      "source": [
        "!pip install wandb -qqq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQX4gFGW4a-q"
      },
      "source": [
        "log to your account"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghxi1Cft4a-q"
      },
      "outputs": [],
      "source": [
        "\n",
        "import wandb\n",
        "\n",
        "WANDB_PROJECT = \"mnist-viz\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeXmvcpx4a-q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "b7c56fc1-a793-47a7-eb0e-d65b0457a29a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maless-marinai\u001b[0m (\u001b[33mflorenceuniversity\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXJG9FO34a-q"
      },
      "source": [
        "# 0. Setup\n",
        "\n",
        "Install dependencies, download MNIST, and create train and test datasets using PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fz5RsS764a-r"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# create train and test dataloaders\n",
        "def get_dataloader(is_train, batch_size, slice=5):\n",
        "    \"Get a training dataloader\"\n",
        "    ds = torchvision.datasets.MNIST(root=\".\", train=is_train, transform=T.ToTensor(), download=True)\n",
        "    loader = torch.utils.data.DataLoader(dataset=ds,\n",
        "                                         batch_size=batch_size,\n",
        "                                         shuffle=True if is_train else False,\n",
        "                                         pin_memory=True, num_workers=2)\n",
        "    return loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkLOxX1Z4a-4"
      },
      "source": [
        "# 1. Define the model and training schedule\n",
        "\n",
        "* Set the number of epochs to run, where each epoch consists of a training step and a validation (test) step. Optionally configure the amount of data to log per test step. Here the number of batches and number of images per batch to visualize are set low to simplify the demo.\n",
        "* Define a simple convolutional neural net (following [pytorch-tutorial](https://github.com/yunjey/pytorch-tutorial) code).\n",
        "* Load in train and test sets using PyTorch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvnHj0az4a-4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ce7a40f-bd76-4002-b39b-24ae5c019e7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 58.1MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.67MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 14.4MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.88MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Number of epochs to run\n",
        "# Each epoch includes a training step and a test step, so this sets\n",
        "# the number of tables of test predictions to log\n",
        "EPOCHS = 1\n",
        "\n",
        "# Number of batches to log from the test data for each test step\n",
        "# (default set low to simplify demo)\n",
        "NUM_BATCHES_TO_LOG = 10 #79\n",
        "\n",
        "# Number of images to log per test batch\n",
        "# (default set low to simplify demo)\n",
        "NUM_IMAGES_PER_BATCH = 32 #128\n",
        "\n",
        "# training configuration and hyperparameters\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.001\n",
        "L1_SIZE = 32\n",
        "L2_SIZE = 64\n",
        "# changing this may require changing the shape of adjacent layers\n",
        "CONV_KERNEL_SIZE = 5\n",
        "\n",
        "# define a two-layer convolutional neural network\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, L1_SIZE, CONV_KERNEL_SIZE, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(L1_SIZE),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(L1_SIZE, L2_SIZE, CONV_KERNEL_SIZE, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(L2_SIZE),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.fc = nn.Linear(7*7*L2_SIZE, NUM_CLASSES)\n",
        "        self.softmax = nn.Softmax(NUM_CLASSES)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # uncomment to see the shape of a given layer:\n",
        "        #print(\"x: \", x.size())\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "train_loader = get_dataloader(is_train=True, batch_size=BATCH_SIZE)\n",
        "test_loader = get_dataloader(is_train=False, batch_size=2*BATCH_SIZE)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62y1pMex4a-5"
      },
      "source": [
        "# 2. Run training and log test predictions\n",
        "\n",
        "For every epoch, run a training step and a test step. For each test step, create a wandb.Table() in which to store test predictions. These can be visualized, dynamically queried, and compared side by side in your browser."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBvotYLt4a-5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "outputId": "f5184255-9fbc-4514-9e47-9e97e39cb3ef"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250408_082956-yv1sqasd</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/florenceuniversity/table-quickstart/runs/yv1sqasd' target=\"_blank\">fallen-dust-4</a></strong> to <a href='https://wandb.ai/florenceuniversity/table-quickstart' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/florenceuniversity/table-quickstart' target=\"_blank\">https://wandb.ai/florenceuniversity/table-quickstart</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/florenceuniversity/table-quickstart/runs/yv1sqasd' target=\"_blank\">https://wandb.ai/florenceuniversity/table-quickstart/runs/yv1sqasd</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1], Step [100/1875], Loss: 0.5858\n",
            "Epoch [1/1], Step [200/1875], Loss: 0.6308\n",
            "Epoch [1/1], Step [300/1875], Loss: 0.3463\n",
            "Epoch [1/1], Step [400/1875], Loss: 0.3598\n",
            "Epoch [1/1], Step [500/1875], Loss: 0.0271\n",
            "Epoch [1/1], Step [600/1875], Loss: 0.0390\n",
            "Epoch [1/1], Step [700/1875], Loss: 0.0903\n",
            "Epoch [1/1], Step [800/1875], Loss: 0.1360\n",
            "Epoch [1/1], Step [900/1875], Loss: 0.0172\n",
            "Epoch [1/1], Step [1000/1875], Loss: 0.0068\n",
            "Epoch [1/1], Step [1100/1875], Loss: 0.0018\n",
            "Epoch [1/1], Step [1200/1875], Loss: 0.1436\n",
            "Epoch [1/1], Step [1300/1875], Loss: 0.0172\n",
            "Epoch [1/1], Step [1400/1875], Loss: 0.1598\n",
            "Epoch [1/1], Step [1500/1875], Loss: 0.0231\n",
            "Epoch [1/1], Step [1600/1875], Loss: 0.0016\n",
            "Epoch [1/1], Step [1700/1875], Loss: 0.1755\n",
            "Epoch [1/1], Step [1800/1875], Loss: 0.0452\n",
            "Test Accuracy of the model on the 10000 test images: 98.34 %\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>█▃▂▂▂▂▃▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▂▁▁▁▂▂▁▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>98.34</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>0.03678</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">fallen-dust-4</strong> at: <a href='https://wandb.ai/florenceuniversity/table-quickstart/runs/yv1sqasd' target=\"_blank\">https://wandb.ai/florenceuniversity/table-quickstart/runs/yv1sqasd</a><br> View project at: <a href='https://wandb.ai/florenceuniversity/table-quickstart' target=\"_blank\">https://wandb.ai/florenceuniversity/table-quickstart</a><br>Synced 5 W&B file(s), 1 media file(s), 322 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250408_082956-yv1sqasd/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ✨ W&B: Initialize a new run to track this model's training\n",
        "wandb.init(project=\"table-quickstart\")\n",
        "\n",
        "# ✨ W&B: Log hyperparameters using config\n",
        "cfg = wandb.config\n",
        "cfg.update({\"epochs\" : EPOCHS, \"batch_size\": BATCH_SIZE, \"lr\" : LEARNING_RATE,\n",
        "            \"l1_size\" : L1_SIZE, \"l2_size\": L2_SIZE,\n",
        "            \"conv_kernel\" : CONV_KERNEL_SIZE,\n",
        "            \"img_count\" : min(10000, NUM_IMAGES_PER_BATCH*NUM_BATCHES_TO_LOG)})\n",
        "\n",
        "# define model, loss, and optimizer\n",
        "model = ConvNet(NUM_CLASSES).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# convenience funtion to log predictions for a batch of test images\n",
        "def log_test_predictions(images, labels, outputs, predicted, test_table, log_counter):\n",
        "  # obtain confidence scores for all classes\n",
        "  scores = F.softmax(outputs.data, dim=1)\n",
        "  log_scores = scores.cpu().numpy()\n",
        "  log_images = images.cpu().numpy()\n",
        "  log_labels = labels.cpu().numpy()\n",
        "  log_preds = predicted.cpu().numpy()\n",
        "  # adding ids based on the order of the images\n",
        "  _id = 0\n",
        "  for i, l, p, s in zip(log_images, log_labels, log_preds, log_scores):\n",
        "    # add required info to data table:\n",
        "    # id, image pixels, model's guess, true label, scores for all classes\n",
        "    img_id = str(_id) + \"_\" + str(log_counter)\n",
        "    test_table.add_data(img_id, wandb.Image(i), p, l, *s)\n",
        "    _id += 1\n",
        "    if _id == NUM_IMAGES_PER_BATCH:\n",
        "      break\n",
        "\n",
        "# train the model\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(EPOCHS):\n",
        "    # training step\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # ✨ W&B: Log loss over training steps, visualized in the UI live\n",
        "        wandb.log({\"loss\" : loss})\n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                .format(epoch+1, EPOCHS, i+1, total_step, loss.item()))\n",
        "\n",
        "\n",
        "    # ✨ W&B: Create a Table to store predictions for each test step\n",
        "    columns=[\"id\", \"image\", \"guess\", \"truth\"]\n",
        "    for digit in range(10):\n",
        "      columns.append(\"score_\" + str(digit))\n",
        "    test_table = wandb.Table(columns=columns)\n",
        "\n",
        "    # test the model\n",
        "    model.eval()\n",
        "    log_counter = 0\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            if log_counter < NUM_BATCHES_TO_LOG:\n",
        "              log_test_predictions(images, labels, outputs, predicted, test_table, log_counter)\n",
        "              log_counter += 1\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        acc = 100 * correct / total\n",
        "        # ✨ W&B: Log accuracy across training epochs, to visualize in the UI\n",
        "        wandb.log({\"epoch\" : epoch, \"acc\" : acc})\n",
        "        print('Test Accuracy of the model on the 10000 test images: {} %'.format(acc))\n",
        "\n",
        "    # ✨ W&B: Log predictions table to wandb\n",
        "    wandb.log({\"test_predictions\" : test_table})\n",
        "\n",
        "# ✨ W&B: Mark the run as complete (useful for multi-cell notebook)\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameters Tuning\n"
      ],
      "metadata": {
        "id": "_FoQO4Q7OByX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJPV-iw15b_L"
      },
      "source": [
        "<img src=\"https://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\" />\n",
        "\n",
        "<!--- @wandbcode{sweeps-video} -->\n",
        "\n",
        "<div><img /></div>\n",
        "\n",
        "<img src=\"https://wandb.me/mini-diagram\" width=\"650\" alt=\"Weights & Biases\" />\n",
        "\n",
        "<div><img /></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iP7ti6C5b_M"
      },
      "source": [
        "Finding a machine learning model that meets your desired metric (such as model accuracy) is normally a redundant task that can take multiple iterations. To make matters worse, it might be unclear which hyperparameter combinations to use for a given training run.\n",
        "\n",
        "Use W&B Sweeps to create an organized and efficient way to automatically search through combinations of hyperparameter values such as the learning rate, batch size, number of hidden layers, optimizer type and more to find values that optimize your model based on your desired metric.\n",
        "\n",
        "In this tutorial you will create a hyperparameter search with W&B PyTorch integration. Follow along with a [video tutorial](http://wandb.me/sweeps-video)!\n",
        "\n",
        "![](https://i.imgur.com/WVKkMWw.png)\n",
        "\n",
        "## Sweeps: An Overview\n",
        "\n",
        "Running a hyperparameter sweep with Weights & Biases is very easy. There are just 3 simple steps:\n",
        "\n",
        "1. **Define the sweep:** we do this by creating a dictionary or a [YAML file](https://docs.wandb.com/library/sweeps/configuration) that specifies the parameters to search through, the search strategy, the optimization metric et all.\n",
        "\n",
        "2. **Initialize the sweep:** with one line of code we initialize the sweep and pass in the dictionary of sweep configurations:\n",
        "`sweep_id = wandb.sweep(sweep_config)`\n",
        "\n",
        "3. **Run the sweep agent:** also accomplished with one line of code, we call `wandb.agent()` and pass the `sweep_id` to run, along with a function that defines your model architecture and trains it:\n",
        "`wandb.agent(sweep_id, function=train)`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPGu-5zb5b_N"
      },
      "source": [
        "## Before you get started\n",
        "\n",
        "Install W&B and import the W&B Python SDK into your notebook:\n",
        "\n",
        "1. Install with `!pip install`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98F6yUQY5b_O"
      },
      "outputs": [],
      "source": [
        "!pip install wandb -Uq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZ35dCb15b_Q"
      },
      "source": [
        "2. Import W&B:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIMR_WSm5b_Q"
      },
      "outputs": [],
      "source": [
        "import wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdtzuCX85b_R"
      },
      "source": [
        "3. Log in to W&B and provide your API key when prompted:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9ei084g5b_R"
      },
      "outputs": [],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AvW0bfX5b_S"
      },
      "source": [
        "## Step 1️: Define a sweep\n",
        "\n",
        "A W&B Sweep combines a strategy for trying numerous hyperparameter values with the code that evaluates them.\n",
        "Before you start a sweep, you must define your sweep strategy with a _sweep configuration_.\n",
        "\n",
        "\n",
        ":::info\n",
        "The sweep configuration you create for a sweep must be in a nested dictionary if you start a sweep in a Jupyter Notebook.\n",
        "\n",
        "If you run a sweep within the command line, you must specify your sweep config with a [YAML file](https://docs.wandb.ai/guides/sweeps/define-sweep-configuration).\n",
        ":::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZTxevGM5b_T"
      },
      "source": [
        "### Pick a search method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_J56ADtZ5b_U"
      },
      "source": [
        "First, specify a hyperparameter search method within your configuration dictionary. [There are three hyperparameter search strategies to choose from: grid, random, and Bayesian search](https://docs.wandb.ai/guides/sweeps/sweep-config-keys#method).\n",
        "\n",
        "For this tutorial, you will use a random search. Within your notebook, create a dictionary and specify `random` for the `method` key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jAcxt065b_V"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    'method': 'random'\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GR9VjO-C5b_V"
      },
      "source": [
        "Specify a metric that you want to optimize for. You do not need to specify the metric and goal for sweeps that use random search method. However, it is good practice to keep track of your sweep goals because you can refer to it at a later time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKULqH7c5b_W"
      },
      "outputs": [],
      "source": [
        "metric = {\n",
        "    'name': 'loss',\n",
        "    'goal': 'minimize'\n",
        "    }\n",
        "\n",
        "sweep_config['metric'] = metric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5h9sbA6dnnXf",
        "outputId": "3e20bcf6-0e20-484c-b0f1-b0cb5105a104"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'method': 'random', 'metric': {'name': 'loss', 'goal': 'minimize'}}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fN-gYZDH5b_W"
      },
      "source": [
        "### Specify hyperparameters to search through\n",
        "\n",
        "Now that you have a search method specified in your sweep configuration, specify the hyperparameters you want to search over.\n",
        "\n",
        "To do this, specify one or more hyperparameter names to the `parameter` key and specify one or more hyperparameter values for the `value` key.\n",
        "\n",
        "The values you search through for a given hyperparamter depend on the the type of hyperparameter you are investigating.  \n",
        "\n",
        "For example, if you choose a machine learning optimizer, you must specify one or more finite optimizer names such as the Adam optimizer and stochastic gradient dissent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilz0ZhwV5b_X"
      },
      "outputs": [],
      "source": [
        "parameters_dict = {\n",
        "    'optimizer': {\n",
        "        'values': ['adam', 'sgd']\n",
        "        },\n",
        "    'fc_layer_size': {\n",
        "        'values': [128, 256, 512]\n",
        "        },\n",
        "    'dropout': {\n",
        "          'values': [0.3, 0.4, 0.5]\n",
        "        },\n",
        "    }\n",
        "\n",
        "sweep_config['parameters'] = parameters_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euHJPf-y5b_X"
      },
      "source": [
        "Sometimes you want to track a hyperparameter, but not vary its value. In this case, add the hyperparameter to your sweep configuration and specify the exact value that you want to use. For example, in the following code cell, `epochs` is set to 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5x4awOF5b_X"
      },
      "outputs": [],
      "source": [
        "parameters_dict.update({\n",
        "    'epochs': {\n",
        "        'value': 1}\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXI-u0uv5b_Y"
      },
      "source": [
        "For a `random` search,\n",
        "all the `values` of a parameter are equally likely to be chosen on a given run.\n",
        "\n",
        "Alternatively,\n",
        "you can specify a named `distribution`,\n",
        "plus its parameters, like the mean `mu`\n",
        "and standard deviation `sigma` of a `normal` distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrCxOHgR5b_Y"
      },
      "outputs": [],
      "source": [
        "parameters_dict.update({\n",
        "    'learning_rate': {\n",
        "        # a flat distribution between 0 and 0.1\n",
        "        'distribution': 'uniform',\n",
        "        'min': 0,\n",
        "        'max': 0.1\n",
        "      },\n",
        "    'batch_size': {\n",
        "        # integers between 32 and 256\n",
        "        # with evenly-distributed logarithms\n",
        "        'distribution': 'q_log_uniform_values',\n",
        "        'q': 8,\n",
        "        'min': 32,\n",
        "        'max': 256,\n",
        "      }\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVQ1SpNB5b_Y"
      },
      "source": [
        "When we're finished, `sweep_config` is a nested dictionary\n",
        "that specifies exactly which `parameters` we're interested in trying\n",
        "and the `method` we're going to use to try them.\n",
        "\n",
        "Let's see how the sweep configuration looks like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfIDOAtC5b_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0937ee8-87d2-40f8-e2e1-c338280bbd27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'method': 'random',\n",
            " 'metric': {'goal': 'minimize', 'name': 'loss'},\n",
            " 'parameters': {'batch_size': {'distribution': 'q_log_uniform_values',\n",
            "                               'max': 256,\n",
            "                               'min': 32,\n",
            "                               'q': 8},\n",
            "                'dropout': {'values': [0.3, 0.4, 0.5]},\n",
            "                'epochs': {'value': 1},\n",
            "                'fc_layer_size': {'values': [128, 256, 512]},\n",
            "                'learning_rate': {'distribution': 'uniform',\n",
            "                                  'max': 0.1,\n",
            "                                  'min': 0},\n",
            "                'optimizer': {'values': ['adam', 'sgd']}}}\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "pprint.pprint(sweep_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-qi92hw5b_Z"
      },
      "source": [
        "For a full list of configuration options, see [Sweep configuration options](https://docs.wandb.ai/guides/sweeps/sweep-config-keys).\n",
        "\n",
        ":::tip\n",
        "For hyperparameters that have potentially infinite options,\n",
        "it usually makes sense to try out\n",
        "a few select `values`. For example, the preceding sweep configuration has a list of finite values specified for the `layer_size` and `dropout` parameter keys.\n",
        ":::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlV7pfsx5b_Z"
      },
      "source": [
        "## Step 2️: Initialize the Sweep\n",
        "\n",
        "Once you've defined the search strategy, it's time to set up something to implement it.\n",
        "\n",
        "W&B uses a Sweep Controller to manage sweeps on the cloud or locally across one or more machines. For this tutorial, you will use a sweep controller managed by W&B.\n",
        "\n",
        "While sweep controllers manage sweeps, the component that actually executes a sweep is known as a _sweep agent_.\n",
        "\n",
        "\n",
        ":::info\n",
        "By default, sweep controllers components are initiated on W&B's servers and sweep agents, the component that creates sweeps, are activated on your local machine.\n",
        ":::\n",
        "\n",
        "\n",
        "Within your notebook, you can activate a sweep controller with the `wandb.sweep` method. Pass your sweep configuration dictionary you defined earlier to the `sweep_config` field:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7mBcL805b_Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5c8a7bb-361f-46a7-e74e-6314ab4f03ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: 9moevmcj\n",
            "Sweep URL: https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj\n"
          ]
        }
      ],
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=\"pytorch-sweeps-demo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-ldLFPI5b_Z"
      },
      "source": [
        "The `wandb.sweep` function returns a `sweep_id` that you will use at a later step to activate your sweep."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72vb37ZB5b_Z"
      },
      "source": [
        ":::info\n",
        "On the command line, this function is replaced with\n",
        "```python\n",
        "wandb sweep config.yaml\n",
        "```\n",
        ":::\n",
        "\n",
        "For more information on how to create W&B Sweeps in a terminal, see the [W&B Sweep walkthrough](https://docs.wandb.com/sweeps/walkthrough).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyxThaCm5b_a"
      },
      "source": [
        "## Step 3:  Define your machine learning code\n",
        "\n",
        "Before you execute the sweep,\n",
        "define the training procedure that uses the hyperparameter values you want to try. The key to integrating W&B Sweeps into your training code is to ensure that, for each training experiment, that your training logic can access the hyperparameter values you defined in your sweep configuration.\n",
        "\n",
        "In the proceeding code example, the helper functions `build_dataset`, `build_network`, `build_optimizer`, and `train_epoch` access the sweep hyperparameter configuration dictionary.\n",
        "\n",
        "Run the proceeding machine learning training code in your notebook. The functions define a basic fully-connected neural network in PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LqjrUdu5b_a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def train(config=None):\n",
        "    # Initialize a new wandb run\n",
        "    with wandb.init(config=config):\n",
        "        # If called by wandb.agent, as below,\n",
        "        # this config will be set by Sweep Controller\n",
        "        config = wandb.config\n",
        "\n",
        "        loader = build_dataset(config.batch_size)\n",
        "        network = build_network(config.fc_layer_size, config.dropout)\n",
        "        optimizer = build_optimizer(network, config.optimizer, config.learning_rate)\n",
        "\n",
        "        for epoch in range(config.epochs):\n",
        "            avg_loss = train_epoch(network, loader, optimizer)\n",
        "            wandb.log({\"loss\": avg_loss, \"epoch\": epoch})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLhxD4KL5b_b"
      },
      "source": [
        "Within the `train` function, you will notice the following W&B Python SDK methods:\n",
        "* [`wandb.init()`](https://docs.wandb.com/library/init) – Initialize a new W&B run. Each run is a single execution of the training function.\n",
        "* [`wandb.config`](https://docs.wandb.com/library/config) – Pass sweep configuration with the hyperparameters you want to experiment with.\n",
        "* [`wandb.log()`](https://docs.wandb.com/library/log) – Log the training loss for each epoch.\n",
        "\n",
        "\n",
        "The proceeding cell defines four functions:\n",
        "`build_dataset`, `build_network`, `build_optimizer`, and `train_epoch`.\n",
        "These functions are a standard part of a basic PyTorch pipeline,\n",
        "and their implementation is unaffected by the use of W&B."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7SRawoK5b_b"
      },
      "outputs": [],
      "source": [
        "def build_dataset(batch_size):\n",
        "\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "         transforms.Normalize((0.1307,), (0.3081,))])\n",
        "    # download MNIST training dataset\n",
        "    dataset = datasets.MNIST(\".\", train=True, download=True,\n",
        "                             transform=transform)\n",
        "    sub_dataset = torch.utils.data.Subset(\n",
        "        dataset, indices=range(0, len(dataset), 5))\n",
        "    loader = torch.utils.data.DataLoader(sub_dataset, batch_size=batch_size)\n",
        "\n",
        "    return loader\n",
        "\n",
        "\n",
        "def build_network(fc_layer_size, dropout):\n",
        "    network = nn.Sequential(  # fully-connected, single hidden layer\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(784, fc_layer_size), nn.ReLU(),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(fc_layer_size, 10),\n",
        "        nn.LogSoftmax(dim=1))\n",
        "\n",
        "    return network.to(device)\n",
        "\n",
        "\n",
        "def build_optimizer(network, optimizer, learning_rate):\n",
        "    if optimizer == \"sgd\":\n",
        "        optimizer = optim.SGD(network.parameters(),\n",
        "                              lr=learning_rate, momentum=0.9)\n",
        "    elif optimizer == \"adam\":\n",
        "        optimizer = optim.Adam(network.parameters(),\n",
        "                               lr=learning_rate)\n",
        "    return optimizer\n",
        "\n",
        "\n",
        "def train_epoch(network, loader, optimizer):\n",
        "    cumu_loss = 0\n",
        "    for _, (data, target) in enumerate(loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # ➡ Forward pass\n",
        "        loss = F.nll_loss(network(data), target)\n",
        "        cumu_loss += loss.item()\n",
        "\n",
        "        # ⬅ Backward pass + weight update\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        wandb.log({\"batch loss\": loss.item()})\n",
        "\n",
        "    return cumu_loss / len(loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ16JG8K5b_b"
      },
      "source": [
        "For more details on instrumenting W&B with PyTorch, see [this Colab](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch/Simple_PyTorch_Integration.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gpr4sgLA5b_b"
      },
      "source": [
        "## Step 4: Activate sweep agents\n",
        "Now that you have your sweep configuration defined and a training script that can utilize those hyperparameter in an interactive way, you are ready to activate a sweep agent. Sweep agents are responsible for running an experiment with a set of hyperparameter values that you defined in your sweep configuration.\n",
        "\n",
        "Create sweep agents with the `wandb.agent` method. Provide the following:\n",
        "1. The sweep the agent is a part of (`sweep_id`)\n",
        "2. The function the sweep is supposed to run. In this example, the sweep will use the `train` function.\n",
        "3. (optionally) How many configs to ask the sweep controller for (`count`)\n",
        "\n",
        ":::tip\n",
        "You can start multiple sweep agents with the same `sweep_id`\n",
        "on different compute resources. The sweep controller ensures that they work together\n",
        "according to the sweep configuration you defined.\n",
        ":::\n",
        "\n",
        "The proceeding cell activates a sweep agent that runs the training function (`train`) 5 times:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-q5OsAh5b_c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "91eb1696-390a-480a-ea6f-21e803a20e2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: j0v99hf8 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 72\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.07322222613539571\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250408_091328-j0v99hf8</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/j0v99hf8' target=\"_blank\">peach-sweep-6</a></strong> to <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/j0v99hf8' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/j0v99hf8</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>▁▅█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>1.81038</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>3.83597</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">peach-sweep-6</strong> at: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/j0v99hf8' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/j0v99hf8</a><br> View project at: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250408_091328-j0v99hf8/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: n6masrrz with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 224\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.09042704215651248\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250408_091338-n6masrrz</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/n6masrrz' target=\"_blank\">frosty-sweep-7</a></strong> to <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/n6masrrz' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/n6masrrz</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>█▇▆▅▄▃▃▂▃▂▃▂▃▂▂▂▂▂▂▃▂▂▂▁▂▁▁▂▁▁▁▂▁▂▁▁▁▁▁▂</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>0.4224</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>0.63068</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">frosty-sweep-7</strong> at: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/n6masrrz' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/n6masrrz</a><br> View project at: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250408_091338-n6masrrz/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: v716i6kn with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 80\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.02024140977265733\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250408_091347-v716i6kn</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/v716i6kn' target=\"_blank\">skilled-sweep-8</a></strong> to <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/v716i6kn' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/v716i6kn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>█▆▇▅▄▅▄▄▆▃▄▆▄▂▂▃▆▃▁▃▃▄▂▃▄▆▃▄▂▄▅▁▂▂▃▅▂▃▃▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>0.44151</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>0.81244</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">skilled-sweep-8</strong> at: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/v716i6kn' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/v716i6kn</a><br> View project at: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250408_091347-v716i6kn/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: k20br2a4 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 192\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.04075065797530489\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250408_091404-k20br2a4</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/k20br2a4' target=\"_blank\">radiant-sweep-9</a></strong> to <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/k20br2a4' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/k20br2a4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>▁▆▅▇█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>1.16532</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>5.13686</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">radiant-sweep-9</strong> at: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/k20br2a4' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/k20br2a4</a><br> View project at: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250408_091404-k20br2a4/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: j788y5av with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 232\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.07072988839699722\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250408_091414-j788y5av</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/j788y5av' target=\"_blank\">gentle-sweep-10</a></strong> to <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/j788y5av' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/j788y5av</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>▁▅▆█▅▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>1.6481</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>11.56544</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">gentle-sweep-10</strong> at: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/j788y5av' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/j788y5av</a><br> View project at: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250408_091414-j788y5av/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zlaayv7b with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 96\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.05665892112316251\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250408_091419-zlaayv7b</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/zlaayv7b' target=\"_blank\">laced-sweep-11</a></strong> to <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/zlaayv7b' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/zlaayv7b</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>▁█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>1.01279</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>6.36187</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">laced-sweep-11</strong> at: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/zlaayv7b' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/zlaayv7b</a><br> View project at: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250408_091419-zlaayv7b/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4awx75ci with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.08895915601739943\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250408_091429-4awx75ci</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/4awx75ci' target=\"_blank\">warm-sweep-12</a></strong> to <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/4awx75ci' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/4awx75ci</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>▁▅▄▆█▆▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>1.30732</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>30.81683</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">warm-sweep-12</strong> at: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/4awx75ci' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/4awx75ci</a><br> View project at: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250408_091429-4awx75ci/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4yjek8l3 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 144\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.08579530398280744\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250408_091445-4yjek8l3</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/4yjek8l3' target=\"_blank\">efficient-sweep-13</a></strong> to <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/4yjek8l3' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/4yjek8l3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>█▆▆▅▄▃▃▃▃▅▃▂▃▄▃▂▂▂▁▂▃▂▃▂▂▂▂▂▂▂▁▁▂▂▂▂▁▂▁▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>0.7346</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>0.62502</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">efficient-sweep-13</strong> at: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/4yjek8l3' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/4yjek8l3</a><br> View project at: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250408_091445-4yjek8l3/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: td6nh52e with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0880401852678567\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250408_091455-td6nh52e</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/td6nh52e' target=\"_blank\">rare-sweep-14</a></strong> to <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/td6nh52e' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/td6nh52e</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>█▅▃▃▂▃▂▂▂▄▁▂▃▃▃▃▄▃▂▁▃▂▄▃▅▂▃▃▂▄▃▅▃▃▃▃▂▂▂▂</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>0.96039</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>1.05896</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">rare-sweep-14</strong> at: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/td6nh52e' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/td6nh52e</a><br> View project at: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250408_091455-td6nh52e/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: li6v6pyf with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 232\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.08510178040082467\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250408_091505-li6v6pyf</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/li6v6pyf' target=\"_blank\">genial-sweep-15</a></strong> to <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/li6v6pyf' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/li6v6pyf</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>█▇▇▆▅▃▂▂▂▃▂▂▂▂▃▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>0.32462</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>0.61693</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">genial-sweep-15</strong> at: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/li6v6pyf' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/li6v6pyf</a><br> View project at: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250408_091505-li6v6pyf/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ub7lk07i with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 120\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.07312088846994085\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250408_091521-ub7lk07i</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/ub7lk07i' target=\"_blank\">driven-sweep-16</a></strong> to <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/ub7lk07i' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/ub7lk07i</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>█▇▆▄▃▃▃▂▄▃▁▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂▁▁▁▁▂▁▁▁▂▂▁▂▁▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>0.22651</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>0.54406</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">driven-sweep-16</strong> at: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/ub7lk07i' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/ub7lk07i</a><br> View project at: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250408_091521-ub7lk07i/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: o4aasgj8 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 48\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0913080875285089\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250408_091537-o4aasgj8</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/o4aasgj8' target=\"_blank\">misunderstood-sweep-17</a></strong> to <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/o4aasgj8' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/o4aasgj8</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>▁█▁▂▁▂▂▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>1.34454</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>4.11458</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">misunderstood-sweep-17</strong> at: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/o4aasgj8' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/o4aasgj8</a><br> View project at: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250408_091537-o4aasgj8/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1gg198oo with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 72\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0573670738455627\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250408_091547-1gg198oo</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/1gg198oo' target=\"_blank\">smart-sweep-18</a></strong> to <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/1gg198oo' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/1gg198oo</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>██▇▅▄▄▂▃▄▂▃▂▃▃▂▁▂▂▃▂▁▃▂▃▂▂▂▂▂▁▂▂▂▂▂▂▂▂▁▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>0.5483</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>0.72028</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">smart-sweep-18</strong> at: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/1gg198oo' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/1gg198oo</a><br> View project at: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250408_091547-1gg198oo/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4hgf2cnj with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.09465795641091906\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250408_091557-4hgf2cnj</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/4hgf2cnj' target=\"_blank\">polished-sweep-19</a></strong> to <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/4hgf2cnj' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/4hgf2cnj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>5.20974</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>9.97464</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">polished-sweep-19</strong> at: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/4hgf2cnj' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/4hgf2cnj</a><br> View project at: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250408_091557-4hgf2cnj/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1aubt073 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_layer_size: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.010628008275383904\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250408_091608-1aubt073</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/1aubt073' target=\"_blank\">polar-sweep-20</a></strong> to <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/sweeps/9moevmcj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/1aubt073' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/1aubt073</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>█▅▅▄▄▃▂▂▃▄▂▂▃▃▃▂▂▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂▁▂▃▂▂▂▂▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch loss</td><td>0.58544</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>0.55538</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">polar-sweep-20</strong> at: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/1aubt073' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo/runs/1aubt073</a><br> View project at: <a href='https://wandb.ai/florenceuniversity/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/florenceuniversity/pytorch-sweeps-demo</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250408_091608-1aubt073/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "wandb.agent(sweep_id, train, count=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQIdat775b_d"
      },
      "source": [
        ":::info\n",
        "Since the `random` search method was specified in the sweep configuration, the sweep controller provides randomly-generated hyperparameter values.\n",
        ":::\n",
        "\n",
        "For more information on how to create W&B Sweeps in a terminal, see the [W&B Sweep walkthrough](https://docs.wandb.com/sweeps/walkthrough)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRvTaW_w5b_d"
      },
      "source": [
        "## Visualize Sweep Results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jusFU_45b_d"
      },
      "source": [
        "\n",
        "### Parallel Coordinates Plot\n",
        "This plot maps hyperparameter values to model metrics. It’s useful for honing in on combinations of hyperparameters that led to the best model performance.\n",
        "\n",
        "![](https://assets.website-files.com/5ac6b7f2924c652fd013a891/5e190366778ad831455f9af2_s_194708415DEC35F74A7691FF6810D3B14703D1EFE1672ED29000BA98171242A5_1578695138341_image.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Z94nr7X5b_d"
      },
      "source": [
        "### Hyperparameter Importance Plot\n",
        "The hyperparameter importance plot surfaces which hyperparameters were the best predictors of your metrics.\n",
        "We report feature importance (from a random forest model) and correlation (implicitly a linear model).\n",
        "\n",
        "![](https://assets.website-files.com/5ac6b7f2924c652fd013a891/5e190367778ad820b35f9af5_s_194708415DEC35F74A7691FF6810D3B14703D1EFE1672ED29000BA98171242A5_1578695757573_image.png)\n",
        "\n",
        "These visualizations can help you save both time and resources running expensive hyperparameter optimizations by honing in on the parameters (and value ranges) that are the most important, and thereby worthy of further exploration.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGUXYZmE5b_d"
      },
      "source": [
        "## Learn more about W&B Sweeps\n",
        "\n",
        "We created a simple training script and [a few flavors of sweep configs](https://github.com/wandb/examples/tree/master/examples/keras/keras-cnn-fashion) for you to play with. We highly encourage you to give these a try.\n",
        "\n",
        "That repo also has examples to help you try more advanced sweep features like [Bayesian Hyperband](https://app.wandb.ai/wandb/examples-keras-cnn-fashion/sweeps/us0ifmrf?workspace=user-lavanyashukla), and [Hyperopt](https://app.wandb.ai/wandb/examples-keras-cnn-fashion/sweeps/xbs2wm5e?workspace=user-lavanyashukla)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EXERCISE\n",
        "\n",
        "Do you remember last lesson? We trained a CNN on the CIFAR10 dataset and got a 40% accuracy. Adapt the code of the last lesson to make it possible to execute an hyperparameter sweep and try to get the highest score in the classification task. In case you lost the code of the last lesson here you can find all the code you will need.\n"
      ],
      "metadata": {
        "id": "qDBbiw86OhdM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#WARNING!!! You just need to get inspired by the following code since you will need to change many parts of it."
      ],
      "metadata": {
        "id": "Lds4vvQURaQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Mapping, Union, Optional\n",
        "\n",
        "import numpy as np\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import plotly.graph_objects as go\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from __future__ import print_function, division"
      ],
      "metadata": {
        "id": "DWJy9luGQFZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tGN_bJOcfd3"
      },
      "outputs": [],
      "source": [
        "# @title reproducibility stuff\n",
        "\n",
        "import random\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(0)\n",
        "\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True  # Note that this Deterministic mode can have a performance impact\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADbJXwrYGpWx"
      },
      "source": [
        "### Load the dataset CIFAR-10\n",
        "\n",
        "Let's ramp things up a bit and consider something harder than MNIST!\n",
        "\n",
        "The CIFAR-10 dataset consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class. These are split into 50,000 training and 10,000 test images.\n",
        "\n",
        "We will use some PyTorch utilities to download, shuffle, normalize the data and arrange it in batches.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Just a function to count the number of parameters\n",
        "def count_parameters(model: torch.nn.Module) -> int:\n",
        "  \"\"\" Counts the number of trainable parameters of a module\n",
        "\n",
        "  :param model: model that contains the parameters to count\n",
        "  :returns: the number of parameters in the model\n",
        "  \"\"\"\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "id": "l4ZmV7nVExY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the device to use: use the gpu runtime if possible!\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using device: {device}')"
      ],
      "metadata": {
        "id": "vXvRduxpEy7R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f0c9abd-7d4f-4a14-9673-3bb46dfd5cd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsOaBrQ9HCVZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eaba32d-23c0-4b91-dabe-e833fe717a67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:14<00:00, 12.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "# quick and dirty just for this notebook\n",
        "image_transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.5,), std=(0.5,)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.CIFAR10(\n",
        "        \"../data\",\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=image_transforms\n",
        "    ),\n",
        "    batch_size=64,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.CIFAR10(\n",
        "        \"../data\",\n",
        "        train=False,\n",
        "        transform=image_transforms\n",
        "    ),\n",
        "    batch_size=1000,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "# Retrieve the image size and the number of color channels\n",
        "x, yy = next(iter(train_loader))\n",
        "\n",
        "n_channels = x.shape[1]\n",
        "input_size_w = x.shape[2]\n",
        "input_size_h = x.shape[3]\n",
        "input_size = input_size_w * input_size_h\n",
        "\n",
        "# Specify the number of classes in CIFAR10\n",
        "output_size = yy.max().item() + 1  # there are 10 classes\n",
        "output_classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "                  'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjIHkUug67Ej",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d0c5ea3-06d4-412a-8a14-214f6d320760"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset CIFAR10\n",
              "    Number of datapoints: 50000\n",
              "    Root location: ../data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               Grayscale(num_output_channels=1)\n",
              "               ToTensor()\n",
              "               Normalize(mean=(0.5,), std=(0.5,))\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Remember that even if we defined a data loader, we can still directly access\n",
        "# the dataset.\n",
        "train_loader.dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dw8vFbaQHOwL"
      },
      "outputs": [],
      "source": [
        "class FC2Layer(nn.Module):\n",
        "    def __init__(\n",
        "        self, input_size: int, input_channels: int, n_hidden: int, output_size: int\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Simple MLP model\n",
        "\n",
        "        :param input_size: number of pixels in the image\n",
        "        :param input_channels: number of color channels in the image\n",
        "        :param n_hidden: size of the hidden dimension to use\n",
        "        :param output_size: expected size of the output (e.g. number of classes if you are in a classification task)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_size * input_channels, n_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(n_hidden, n_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(n_hidden, output_size),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        :param x: batch of images with size [batch, 1, w, h]\n",
        "\n",
        "        :returns: predictions with size [batch, output_size]\n",
        "        \"\"\"\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        o = self.network(x)\n",
        "        return o\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(\n",
        "        self, input_size: int, input_channels: int, n_feature: int, output_size: int\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Simple model that uses 3x3 convolutions\n",
        "\n",
        "        :param input_size: number of pixels in the image\n",
        "        :param input_channels: number of color channels in the image\n",
        "        :param n_feature: size of the hidden dimensions to use (i.e. output channels for the conv layers)\n",
        "        :param output_size: expected size of the output\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.n_feature = n_feature\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=input_channels, out_channels=n_feature, kernel_size=3\n",
        "        )\n",
        "        self.conv2 = nn.Conv2d(n_feature, n_feature, kernel_size=3)\n",
        "        self.conv3 = nn.Conv2d(n_feature, n_feature, kernel_size=3)\n",
        "\n",
        "        self.fc1 = nn.Linear(n_feature * 5 * 5, output_size)  # how did we choose those 5? keep reading!\n",
        "        self.fc2 = nn.Linear(output_size, output_size)\n",
        "\n",
        "    def forward(self,\n",
        "                x: torch.Tensor,\n",
        "                return_conv1: bool = False,\n",
        "                return_conv2: bool = False,\n",
        "                return_conv3: bool = False\n",
        "        ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        :param x: batch of images with size [batch, 1, w, h]\n",
        "        :param return_conv1: if True return the feature maps of the first convolution\n",
        "        :param return_conv2: if True return the feature maps of the second convolution\n",
        "        :param return_conv3: if True return the feature maps of the third convolution\n",
        "\n",
        "        :returns: predictions with size [batch, output_size]\n",
        "        \"\"\"\n",
        "        x = self.conv1(x)\n",
        "        if return_conv1:\n",
        "            return x\n",
        "\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, kernel_size=2)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        if return_conv2:\n",
        "            return x\n",
        "\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # Not so easy to keep track of shapes... right?\n",
        "        # A useful trick while debugging is to feed the model a fixed sample batch,\n",
        "        # and print the shape at each step, just to make sure that they match your expectations.\n",
        "\n",
        "        # print(x.shape)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        if return_conv3:\n",
        "            return x\n",
        "\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, kernel_size=2)\n",
        "\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.fc1(x)\n",
        "\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# A fixed sample batch\n",
        "# x, _ = next(iter(train_loader))\n",
        "# model = CNN(input_size, n_channels, 9, 10)\n",
        "# _ = model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bf_B4Mk0HV5T"
      },
      "outputs": [],
      "source": [
        "# You can skip this cell and read only the function docstring\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from typing import Optional, Callable, Dict\n",
        "from tqdm.notebook import tqdm, trange\n",
        "\n",
        "\n",
        "def permute_pixels(images: torch.Tensor, perm: Optional[torch.Tensor]) -> torch.Tensor:\n",
        "    \"\"\" Permutes the pixel in each image in the batch\n",
        "\n",
        "    :param images: a batch of images with shape [batch, channels, w, h]\n",
        "    :param perm: a permutation with shape [w * h]\n",
        "\n",
        "    :returns: the batch of images permuted according to perm\n",
        "    \"\"\"\n",
        "    if perm is None:\n",
        "        return images\n",
        "\n",
        "    batch_size = images.shape[0]\n",
        "    n_channels = images.shape[1]\n",
        "    w = images.shape[2]\n",
        "    h = images.shape[3]\n",
        "    images = images.view(batch_size, n_channels, -1)\n",
        "    images = images[..., perm]\n",
        "    images = images.view(batch_size, n_channels, w, h)\n",
        "    return images\n",
        "\n",
        "\n",
        "def make_averager() -> Callable[[Optional[float]], float]:\n",
        "    \"\"\" Returns a function that maintains a running average\n",
        "\n",
        "    :returns: running average function\n",
        "    \"\"\"\n",
        "    count = 0\n",
        "    total = 0\n",
        "\n",
        "    def averager(new_value: Optional[float]) -> float:\n",
        "        \"\"\" Running averager\n",
        "\n",
        "        :param new_value: number to add to the running average,\n",
        "                          if None returns the current average\n",
        "        :returns: the current average\n",
        "        \"\"\"\n",
        "        nonlocal count, total\n",
        "        if new_value is None:\n",
        "            return total / count if count else float(\"nan\")\n",
        "        count += 1\n",
        "        total += new_value\n",
        "        return total / count\n",
        "\n",
        "    return averager\n",
        "\n",
        "def test_model(\n",
        "    test_dl: torch.utils.data.DataLoader,\n",
        "    model: torch.nn.Module,\n",
        "    perm: Optional[torch.Tensor] = None,\n",
        "    device: str = \"cuda\",\n",
        ") -> Dict[str, Union[float, Callable[[Optional[float]], float]]]:\n",
        "    \"\"\"Compute model accuracy on the test set\n",
        "\n",
        "    :param test_dl: the test dataloader\n",
        "    :param model: the model to train\n",
        "    :param perm: if not None, permute the pixel in each image according to perm\n",
        "\n",
        "    :returns: computed accuracy\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    test_loss_averager = make_averager()  # mantain a running average of the loss\n",
        "    correct = 0\n",
        "    for data, target in test_dl:\n",
        "        # send to device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        if perm is not None:\n",
        "            data = permute_pixels(data, perm)\n",
        "\n",
        "        output = model(data)\n",
        "\n",
        "        test_loss_averager(F.cross_entropy(output, target))\n",
        "\n",
        "        # get the index of the max probability\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.view_as(pred)).cpu().sum().item()\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": 100.0 * correct / len(test_dl.dataset),\n",
        "        \"loss_averager\": test_loss_averager,\n",
        "        \"correct\": correct,\n",
        "    }\n",
        "\n",
        "def fit(\n",
        "    epochs: int,\n",
        "    train_dl: torch.utils.data.DataLoader,\n",
        "    test_dl: torch.utils.data.DataLoader,\n",
        "    model: torch.nn.Module,\n",
        "    opt: torch.optim.Optimizer,\n",
        "    tag: str,\n",
        "    perm: Optional[torch.Tensor] = None,\n",
        "    device: str = \"cuda\",\n",
        ") -> float:\n",
        "    \"\"\"Train the model and computes metrics on the test_loader at each epoch\n",
        "\n",
        "    :param epochs: number of epochs\n",
        "    :param train_dl: the train dataloader\n",
        "    :param test_dl: the test dataloader\n",
        "    :param model: the model to train\n",
        "    :param opt: the optimizer to use to train the model\n",
        "    :param tag: description of the current model\n",
        "    :param perm: if not None, permute the pixel in each image according to perm\n",
        "\n",
        "    :returns: accucary on the test set in the last epoch\n",
        "    \"\"\"\n",
        "    for epoch in trange(epochs, desc=\"train epoch\"):\n",
        "        model.train()\n",
        "        train_loss_averager = make_averager()  # mantain a running average of the loss\n",
        "\n",
        "        # TRAIN\n",
        "        tqdm_iterator = tqdm(\n",
        "            enumerate(train_dl),\n",
        "            total=len(train_dl),\n",
        "            desc=f\"batch [loss: None]\",\n",
        "            leave=False,\n",
        "        )\n",
        "        for batch_idx, (data, target) in tqdm_iterator:\n",
        "            # send to device\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            if perm is not None:\n",
        "                data = permute_pixels(data, perm)\n",
        "\n",
        "            output = model(data)\n",
        "            loss = F.cross_entropy(output, target)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "\n",
        "            train_loss_averager(loss.item())\n",
        "\n",
        "            tqdm_iterator.set_description(\n",
        "                f\"train batch [avg loss: {train_loss_averager(None):.3f}]\"\n",
        "            )\n",
        "            tqdm_iterator.refresh()\n",
        "\n",
        "        # TEST\n",
        "        test_out = test_model(test_dl, model, perm, device)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch: {epoch}\\n\"\n",
        "            f\"Train set: Average loss: {train_loss_averager(None):.4f}\\n\"\n",
        "            f\"Test set: Average loss: {test_out['loss_averager'](None):.4f}, \"\n",
        "            f\"Accuracy: {test_out['correct']}/{len(test_dl.dataset)} \"\n",
        "            f\"({test_out['accuracy']:.0f}%)\\n\"\n",
        "        )\n",
        "    models_accuracy[tag] = test_out['accuracy']\n",
        "    return test_out['accuracy']\n",
        "\n",
        "\n",
        "\n",
        "def get_model_optimizer(model: torch.nn.Module) -> torch.optim.Optimizer:\n",
        "    \"\"\"\n",
        "    Encapsulate the creation of the model's optimizer, to ensure that we use the\n",
        "    same optimizer everywhere\n",
        "\n",
        "    :param model: the model that contains the parameters to optimize\n",
        "\n",
        "    :returns: the model's optimizer\n",
        "    \"\"\"\n",
        "    return optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "    # return optim.SGD(model.parameters(), lr=0.01, momentum=0.1, weight_decay=1e-5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0P5wyMj0f1-0"
      },
      "outputs": [],
      "source": [
        "# Define the number of the epochs\n",
        "epochs = 4\n",
        "\n",
        "# Number of hidden units for the MLP (hidden units = neurons = rows of the weight matrix)\n",
        "n_hidden = 9\n",
        "\n",
        "# Number of the feature maps in the CNN (feature maps = output channels resulting from convolutions)\n",
        "n_features = 6\n",
        "\n",
        "# Define a global dictionary to store the performance of the different models\n",
        "models_accuracy = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqsZ7Q_-HnjN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362,
          "referenced_widgets": [
            "e600e3d3a5fe4509a79dbe577568ac4e",
            "f61ec96e35514d0597155480323710c4",
            "aa815adae69f441cb252cf5443ff463c",
            "b4738d0ba44e4b95b284741bdd27b06a",
            "929519f9241a49bebc7dfb657c6fed17",
            "c3d6841a96c84147b448df663d410360",
            "93ceccba8eef4cab8d6d96a5fde37085",
            "3cedcfd89ee94e45a51728cebfc03ac0",
            "22566706e5564314b739832762435ecb",
            "7e5c67c5674447ee9970e711afb87c02",
            "442adcdf9d8043658dc0cf14e94e30e3",
            "f7d91d1661cb4abb94dafb2f9325c2d3",
            "6f31593dc75448a1801c43151a8efe5c",
            "39a6c23edf644daead01b73177cd21d6",
            "6fcd435e1dcf4c068dcd1f27fca82620",
            "2f95c3f0417f463d8a52b79cf0c18605",
            "f67827b111ec4dc0974b0434b36a51a7",
            "6a3284b871834db7a21f4022d85264e2",
            "c2fb31d311244ffc95366034d1e2130f",
            "c28332ec538143439ccd191b0483dd4d",
            "46d9e64009db47f5bb39ed6ff171d469",
            "90e97869c685418f97410e6adc3be31d",
            "7a128fcf49f94a8ea727e53420608b16",
            "babd464651dd4af49698aeca1ba199fb",
            "4a8396fb761b4d138a1941f7eea14855",
            "d4ee926f666b454c889b5021f203d067",
            "3677133800db4a3c9c0e5a95be438e13",
            "b50774d394e34b259744cacf52784564",
            "231139aa976542f9b3ad486acb8c2bd5",
            "b30bbe27b2f14c3fac24196788e2ed85",
            "5dee94a5c0e54ffe88d255dfbd97f7af",
            "5234e5de8f6246f8a6651fcc31668bbd",
            "e024b65567774259bbb29f0fd8d71f60",
            "b6dc02da46e74d5fab8759d17f4c048b",
            "2e6e6c7ea1e8472d988946f2e26d5170",
            "6d3081f4b7aa46109475d52b37e85902",
            "0c05f9deed804d60bd22a7f0f29923eb",
            "49fabe3bb9a9490c8c99773f820908e0",
            "8a70774fa2ad45849a82256ffd5adeb3",
            "f8a60e86d6b04102916d923f9d171f22",
            "43f67138c2c242eab7a7dd2622ff6e04",
            "007ce749a14643fe8be9a81a0ecf0f4c",
            "7b14b10f04ba40d6bbb749470f3f8647",
            "976c5e39c60e4b97a78f4315011c253f",
            "6ef52d9465994d2281bc5f0659aaffda",
            "1fec857d989848fb83df03f7bec1e5be",
            "0f232711257c4d41bee28d37c77c6b6a",
            "b05deceb69034c99a69cb0c4c61afd7e",
            "6bf09f5ee5cd46feaad28b16d95b433c",
            "86abf031dcd241dcb279128324018ec1",
            "c473be084b594e869a6a6ae1e227968a",
            "0d5be7de7ae44b6a8038398228f121d3",
            "4d8bd320dbcb4af0b0e6626dcd4fdc54",
            "752dd590ff38428e9e36668271d21d22",
            "3ed607149a604888a6b8a49ddade04f4"
          ]
        },
        "outputId": "d1204d60-ca94-4911-d77c-f2b9cf2c1250"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 9415\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e600e3d3a5fe4509a79dbe577568ac4e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "batch [loss: None]:   0%|          | 0/782 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7d91d1661cb4abb94dafb2f9325c2d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "Train set: Average loss: 2.0700\n",
            "Test set: Average loss: 1.9685, Accuracy: 2820/10000 (28%)\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "batch [loss: None]:   0%|          | 0/782 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a128fcf49f94a8ea727e53420608b16"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "Train set: Average loss: 1.9440\n",
            "Test set: Average loss: 1.9261, Accuracy: 3033/10000 (30%)\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "batch [loss: None]:   0%|          | 0/782 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6dc02da46e74d5fab8759d17f4c048b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2\n",
            "Train set: Average loss: 1.9089\n",
            "Test set: Average loss: 1.9079, Accuracy: 3083/10000 (31%)\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "batch [loss: None]:   0%|          | 0/782 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ef52d9465994d2281bc5f0659aaffda"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3\n",
            "Train set: Average loss: 1.8902\n",
            "Test set: Average loss: 1.8961, Accuracy: 3158/10000 (32%)\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31.58"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "model_fnn = FC2Layer(input_size, n_channels, n_hidden, output_size)\n",
        "model_fnn.to(device)\n",
        "optimizer = get_model_optimizer(model_fnn)\n",
        "\n",
        "print(f'Number of parameters: {count_parameters(model_fnn)}')\n",
        "\n",
        "fit(epochs=epochs,\n",
        "    train_dl=train_loader,\n",
        "    test_dl=test_loader,\n",
        "    model=model_fnn,\n",
        "    opt=optimizer,\n",
        "    tag='fnn',\n",
        "    device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Write your code here!!!"
      ],
      "metadata": {
        "id": "RnZiTa62SszH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code..."
      ],
      "metadata": {
        "id": "gXAdRKnOSz6g"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Lds4vvQURaQJ"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}